{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/data-science-bowl-2019/sample_submission.csv\n",
      "/kaggle/input/data-science-bowl-2019/specs.csv\n",
      "/kaggle/input/data-science-bowl-2019/train_labels.csv\n",
      "/kaggle/input/data-science-bowl-2019/train.csv\n",
      "/kaggle/input/data-science-bowl-2019/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from xgboost import plot_importance\n",
    "from catboost import CatBoostRegressor\n",
    "from matplotlib import pyplot\n",
    "from bayes_opt import BayesianOptimization\n",
    "import shap\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "from time import time\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import cohen_kappa_score, mean_squared_error\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import gc\n",
    "import json\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "np.random.seed(566)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "random.seed(28)\n",
    "np.random.seed(28)\n",
    "\n",
    "import os\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "from collections import defaultdict\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cat\n",
    "import time\n",
    "from collections import Counter\n",
    "import datetime\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold, GroupKFold, GridSearchCV, train_test_split, TimeSeriesSplit, RepeatedStratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn import linear_model\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from bayes_opt import BayesianOptimization\n",
    "import eli5\n",
    "import shap\n",
    "from IPython.display import HTML\n",
    "import json\n",
    "import altair as alt\n",
    "from category_encoders.ordinal import OrdinalEncoder\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from typing import List\n",
    "\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import gc\n",
    "from numba import jit\n",
    "\n",
    "from functools import partial\n",
    "import scipy as sp\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostRegressor, CatBoostClassifier\n",
    "from sklearn import metrics\n",
    "from typing import Any\n",
    "from itertools import product\n",
    "pd.set_option('max_rows', 500)\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "# Objective\n",
    "\n",
    "* In the last notebook we create our baseline model including a feature selection part. \n",
    "* Cohen cappa score of 0.456 (lb) with a local cv score of 0.529\n",
    "* In this notebook we are going to add more features and remove others that i think they overfitt the train set and then check if our local cv score improve.\n",
    "* Next, we will check if this improvement aligns with the lb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "* Check the distribution of the target variable of the out of folds score and the prediction distribution. A good model should more or less have the same distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_qwk_lgb_regr(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fast cappa eval function for lgb.\n",
    "    \"\"\"\n",
    "    dist = Counter(reduce_train['accuracy_group'])\n",
    "    for k in dist:\n",
    "        dist[k] /= len(reduce_train)\n",
    "    reduce_train['accuracy_group'].hist()\n",
    "    \n",
    "    acum = 0\n",
    "    bound = {}\n",
    "    for i in range(3):\n",
    "        acum += dist[i]\n",
    "        bound[i] = np.percentile(y_pred, acum * 100)\n",
    "\n",
    "    def classify(x):\n",
    "        if x <= bound[0]:\n",
    "            return 0\n",
    "        elif x <= bound[1]:\n",
    "            return 1\n",
    "        elif x <= bound[2]:\n",
    "            return 2\n",
    "        else:\n",
    "            return 3\n",
    "\n",
    "    y_pred = np.array(list(map(classify, y_pred))).reshape(y_true.shape)\n",
    "\n",
    "    return 'cappa', cohen_kappa_score(y_true, y_pred, weights='quadratic'), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohenkappa(ypred, y):\n",
    "    y = y.get_label().astype(\"int\")\n",
    "    ypred = ypred.reshape((4, -1)).argmax(axis = 0)\n",
    "    loss = cohenkappascore(y, y_pred, weights = 'quadratic')\n",
    "    return \"cappa\", loss, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    print('Reading train.csv file....')\n",
    "    train = pd.read_csv('/kaggle/input/data-science-bowl-2019/train.csv')\n",
    "    print('Training.csv file have {} rows and {} columns'.format(train.shape[0], train.shape[1]))\n",
    "\n",
    "    print('Reading test.csv file....')\n",
    "    test = pd.read_csv('/kaggle/input/data-science-bowl-2019/test.csv')\n",
    "    print('Test.csv file have {} rows and {} columns'.format(test.shape[0], test.shape[1]))\n",
    "\n",
    "    print('Reading train_labels.csv file....')\n",
    "    train_labels = pd.read_csv('/kaggle/input/data-science-bowl-2019/train_labels.csv')\n",
    "    print('Train_labels.csv file have {} rows and {} columns'.format(train_labels.shape[0], train_labels.shape[1]))\n",
    "\n",
    "    print('Reading specs.csv file....')\n",
    "    specs = pd.read_csv('/kaggle/input/data-science-bowl-2019/specs.csv')\n",
    "    print('Specs.csv file have {} rows and {} columns'.format(specs.shape[0], specs.shape[1]))\n",
    "\n",
    "    print('Reading sample_submission.csv file....')\n",
    "    sample_submission = pd.read_csv('/kaggle/input/data-science-bowl-2019/sample_submission.csv')\n",
    "    print('Sample_submission.csv file have {} rows and {} columns'.format(sample_submission.shape[0], sample_submission.shape[1]))\n",
    "    return train, test, train_labels, specs, sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_title(train, test, train_labels):\n",
    "    # encode title\n",
    "    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n",
    "    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n",
    "    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n",
    "    # make a list with all the unique 'titles' from the train and test set\n",
    "    list_of_user_activities = list(set(train['title'].unique()).union(set(test['title'].unique())))\n",
    "    # make a list with all the unique 'event_code' from the train and test set\n",
    "    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n",
    "    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n",
    "    # make a list with all the unique worlds from the train and test set\n",
    "    list_of_worlds = list(set(train['world'].unique()).union(set(test['world'].unique())))\n",
    "    # create a dictionary numerating the titles\n",
    "    activities_map = dict(zip(list_of_user_activities, np.arange(len(list_of_user_activities))))\n",
    "    activities_labels = dict(zip(np.arange(len(list_of_user_activities)), list_of_user_activities))\n",
    "    activities_world = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n",
    "    assess_titles = list(set(train[train['type'] == 'Assessment']['title'].value_counts().index).union(set(test[test['type'] == 'Assessment']['title'].value_counts().index)))\n",
    "    # replace the text titles with the number titles from the dict\n",
    "    train['title'] = train['title'].map(activities_map)\n",
    "    test['title'] = test['title'].map(activities_map)\n",
    "    train['world'] = train['world'].map(activities_world)\n",
    "    test['world'] = test['world'].map(activities_world)\n",
    "    train_labels['title'] = train_labels['title'].map(activities_map)\n",
    "    win_code = dict(zip(activities_map.values(), (4100*np.ones(len(activities_map))).astype('int')))\n",
    "    # then, it set one element, the 'Bird Measurer (Assessment)' as 4110, 10 more than the rest\n",
    "    win_code[activities_map['Bird Measurer (Assessment)']] = 4110\n",
    "    # convert text into datetime\n",
    "    train['timestamp'] = pd.to_datetime(train['timestamp'])\n",
    "    test['timestamp'] = pd.to_datetime(test['timestamp'])\n",
    "    \n",
    "    train['hour'] = train['timestamp'].dt.hour\n",
    "    test['hour'] = test['timestamp'].dt.hour\n",
    "    train['weekday'] = train['timestamp'].dt.weekday\n",
    "    test['weekday'] = test['timestamp'].dt.weekday\n",
    "    \n",
    "    return train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clip_time = {'Welcome to Lost Lagoon!':19,'Tree Top City - Level 1':17,'Ordering Spheres':61, 'Costume Box':61,\n",
    "        '12 Monkeys':109,'Tree Top City - Level 2':25, 'Pirate\\'s Tale':80, 'Treasure Map':156,'Tree Top City - Level 3':26,\n",
    "        'Rulers':126, 'Magma Peak - Level 1':20, 'Slop Problem':60, 'Magma Peak - Level 2':22, 'Crystal Caves - Level 1':18,\n",
    "        'Balancing Act':72, 'Lifting Heavy Things':118,'Crystal Caves - Level 2':24, 'Honey Cake':142, 'Crystal Caves - Level 3':19,\n",
    "        'Heavy, Heavier, Heaviest':61}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the function that convert the raw data into processed features\n",
    "def get_data(user_sample, test_set=False):\n",
    "    '''\n",
    "    The user_sample is a DataFrame from train or test where the only one \n",
    "    installation_id is filtered\n",
    "    And the test_set parameter is related with the labels processing, that is only requered\n",
    "    if test_set=False\n",
    "    '''\n",
    "    # Constants and parameters declaration\n",
    "    last_activity = 0\n",
    "    \n",
    "    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "    \n",
    "    # new features: time spent in each activity\n",
    "    last_session_time_sec = 0\n",
    "    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n",
    "    all_assessments = []\n",
    "    accumulated_accuracy_group = 0\n",
    "    accumulated_accuracy = 0\n",
    "    accumulated_correct_attempts = 0 \n",
    "    accumulated_uncorrect_attempts = 0\n",
    "    accumulated_actions = 0\n",
    "    counter = 0\n",
    "    time_first_activity = float(user_sample['timestamp'].values[0])\n",
    "    \n",
    "    durations = []\n",
    "    clip_durations = []\n",
    "    Activity_durations = []\n",
    "    Game_durations = []\n",
    "    \n",
    "    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n",
    "    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n",
    "    game_event_code_count: Dict[str, int] = { str(ev) + '_g': 0 for ev in list_of_event_code}\n",
    "    Activity_event_code_count: Dict[str, int] = {str(ev) + '_A': 0 for ev in list_of_event_code}    \n",
    "    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n",
    "    Activity_sum_event_count = 0\n",
    "    game_sum_event_count = 0\n",
    "#     game_event_id_count: Dict[str, int] = {eve+'_g': 0 for eve in list_of_event_id}\n",
    "#     Activity_event_id_count: Dict[str, int] = {eve+'_A': 0 for eve in list_of_event_id}\n",
    "#     Accessment_event_id_count: Dict[str, int] = {eve+'_ac': 0 for eve in list_of_event_id}\n",
    "    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n",
    "    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n",
    "        \n",
    "    # last features\n",
    "    sessions_count = 0\n",
    "    \n",
    "    # itarates through each session of one instalation_id\n",
    "    for i, session in user_sample.groupby('game_session', sort=False):\n",
    "        # i = game_session_id\n",
    "        # session is a DataFrame that contain only one game_session\n",
    "        \n",
    "        # get some sessions information\n",
    "        session_type = session['type'].iloc[0]\n",
    "        session_title = session['title'].iloc[0]\n",
    "        session_title_text = activities_labels[session_title]\n",
    "        \n",
    "        if session_type == 'Clip':\n",
    "            clip_durations.append((clip_time[activities_labels[session_title]]))\n",
    "        \n",
    "        if session_type == 'Activity':\n",
    "            Activity_sum_event_count = Activity_sum_event_count + session['event_count'].iloc[-1]\n",
    "            Activity_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = str(k) + '_A'\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            Activity_event_code_count = update_counters(Activity_event_code_count, \"event_code\")\n",
    "#             def update_counters_id(counter: dict, col: str):\n",
    "#                 num_of_session_count = Counter(session[col])\n",
    "#                 for k in num_of_session_count.keys():\n",
    "#                     x = k + '_g'\n",
    "#                     if col == 'title':\n",
    "#                         x = activities_labels[k]\n",
    "#                     counter[x] += num_of_session_count[k]\n",
    "#                 return counter\n",
    "#             Activity_event_id_count = update_counters(Activity_event_id_count, \"event_id\")\n",
    "        \n",
    "        if session_type == 'Game':\n",
    "            game_sum_event_count = game_sum_event_count + session['event_count'].iloc[-1]\n",
    "            Game_durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = str(k) + '_g'\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            game_event_code_count = update_counters(game_event_code_count, \"event_code\")\n",
    "#             def update_counters_id(counter: dict, col: str):\n",
    "#                 num_of_session_count = Counter(session[col])\n",
    "#                 for k in num_of_session_count.keys():\n",
    "#                     x = k + '_g'\n",
    "#                     if col == 'title':\n",
    "#                         x = activities_labels[k]\n",
    "#                     counter[x] += num_of_session_count[k]\n",
    "#                 return counter\n",
    "#             game_event_id_count = update_counters(game_event_id_count, \"event_id\")\n",
    "\n",
    "        # for each assessment, and only this kind off session, the features below are processed\n",
    "        # and a register are generated\n",
    "        if (session_type == 'Assessment') & (test_set or len(session)>1):\n",
    "            # search for event_code 4100, that represents the assessments trial\n",
    "            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n",
    "            # then, check the numbers of wins and the number of losses\n",
    "            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n",
    "            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n",
    "            # copy a dict to use as feature template, it's initialized with some itens: \n",
    "            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n",
    "            features = user_activities_count.copy()\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features.update(event_code_count.copy())\n",
    "            features.update(event_id_count.copy())\n",
    "            \n",
    "            features.update(game_event_code_count.copy())\n",
    "#             features.update(game_event_id_count.copy())\n",
    "            features.update(Activity_event_code_count.copy())\n",
    "#             features.update(Activity_event_id_count.copy())\n",
    "#             features.update(Accessment_event_id_count.copy())\n",
    "            \n",
    "            features.update(title_count.copy())\n",
    "            features.update(title_event_code_count.copy())\n",
    "            features.update(last_accuracy_title.copy())\n",
    "            features['installation_session_count'] = sessions_count\n",
    "            features['hour'] = session['hour'].iloc[-1]\n",
    "            features['weekday'] = session['weekday'].iloc[-1]\n",
    "            variety_features = [('var_event_code', event_code_count),\n",
    "                              ('var_event_id', event_id_count),\n",
    "                               ('var_title', title_count),\n",
    "                               ('var_title_event_code', title_event_code_count)]\n",
    "            \n",
    "            for name, dict_counts in variety_features:\n",
    "                arr = np.array(list(dict_counts.values()))\n",
    "                features[name] = np.count_nonzero(arr)\n",
    "                 \n",
    "            # get installation_id for aggregated features\n",
    "            features['installation_id'] = session['installation_id'].iloc[-1]\n",
    "            # add title as feature, remembering that title represents the name of the game\n",
    "            features['session_title'] = session['title'].iloc[0]\n",
    "            # the 4 lines below add the feature of the history of the trials of this player\n",
    "            # this is based on the all time attempts so far, at the moment of this assessment\n",
    "            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n",
    "            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n",
    "            features['game_sum_event_count'] = game_sum_event_count\n",
    "            features['Activity_sum_event_count'] = game_sum_event_count\n",
    "            accumulated_correct_attempts += true_attempts \n",
    "            accumulated_uncorrect_attempts += false_attempts\n",
    "            # the time spent in the app so far\n",
    "            if durations == []:\n",
    "                features['duration_mean'] = 0\n",
    "                features['duration_std'] = 0\n",
    "            else:\n",
    "                features['duration_mean'] = np.mean(durations)\n",
    "                features['duration_std'] = np.std(durations)\n",
    "                \n",
    "            if clip_durations == []:\n",
    "                features['Clip_duration_mean'] = 0\n",
    "                features['Clip_duration_std'] = 0\n",
    "            else:\n",
    "                features['Clip_duration_mean'] = np.mean(clip_durations)\n",
    "                features['Clip_duration_std'] = np.std(clip_durations)\n",
    "                \n",
    "            if Activity_durations == []:\n",
    "                features['Activity_duration_mean'] = 0\n",
    "                features['Activity_duration_std'] = 0\n",
    "            else:\n",
    "                features['Activity_duration_mean'] = np.mean(Activity_durations)\n",
    "                features['Activity_duration_std'] = np.std(Activity_durations)\n",
    "                \n",
    "            if Game_durations == []:\n",
    "                features['Game_duration_mean'] = 0\n",
    "                features['Game_duration_std'] = 0\n",
    "            else:\n",
    "                features['Game_duration_mean'] = np.mean(Game_durations)\n",
    "                features['Game_duration_std'] = np.std(Game_durations)\n",
    "                \n",
    "            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n",
    "            # the accurace is the all time wins divided by the all time attempts\n",
    "            features['accumulated_accuracy'] = accumulated_accuracy/counter if counter > 0 else 0\n",
    "            accuracy = true_attempts/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n",
    "            accumulated_accuracy += accuracy\n",
    "            last_accuracy_title['acc_' + session_title_text] = accuracy\n",
    "            # a feature of the current accuracy categorized\n",
    "            # it is a counter of how many times this player was in each accuracy group\n",
    "            if accuracy == 0:\n",
    "                features['accuracy_group'] = 0\n",
    "            elif accuracy == 1:\n",
    "                features['accuracy_group'] = 3\n",
    "            elif accuracy == 0.5:\n",
    "                features['accuracy_group'] = 2\n",
    "            else:\n",
    "                features['accuracy_group'] = 1\n",
    "            features.update(accuracy_groups)\n",
    "            accuracy_groups[features['accuracy_group']] += 1\n",
    "            # mean of the all accuracy groups of this player\n",
    "            features['accumulated_accuracy_group'] = accumulated_accuracy_group/counter if counter > 0 else 0\n",
    "            accumulated_accuracy_group += features['accuracy_group']\n",
    "            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n",
    "            features['accumulated_actions'] = accumulated_actions\n",
    "            \n",
    "            # there are some conditions to allow this features to be inserted in the datasets\n",
    "            # if it's a test set, all sessions belong to the final dataset\n",
    "            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n",
    "            # that means, must exist an event_code 4100 or 4110\n",
    "            if test_set:\n",
    "                all_assessments.append(features)\n",
    "            elif true_attempts+false_attempts > 0:\n",
    "                all_assessments.append(features)  \n",
    "            counter += 1\n",
    "        \n",
    "        sessions_count += 1\n",
    "        # this piece counts how many actions was made in each event_code so far\n",
    "        def update_counters(counter: dict, col: str):\n",
    "                num_of_session_count = Counter(session[col])\n",
    "                for k in num_of_session_count.keys():\n",
    "                    x = k\n",
    "                    if col == 'title':\n",
    "                        x = activities_labels[k]\n",
    "                    counter[x] += num_of_session_count[k]\n",
    "                return counter\n",
    "            \n",
    "        event_code_count = update_counters(event_code_count, \"event_code\")\n",
    "        event_id_count = update_counters(event_id_count, \"event_id\")\n",
    "        title_count = update_counters(title_count, 'title')\n",
    "        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n",
    "\n",
    "        # counts how many actions the player has done so far, used in the feature of the same name\n",
    "        accumulated_actions += len(session)\n",
    "        if last_activity != session_type:\n",
    "            user_activities_count[session_type] += 1\n",
    "            last_activitiy = session_type \n",
    "                        \n",
    "    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n",
    "    if test_set:\n",
    "        return all_assessments[-1]\n",
    "    # in the train_set, all assessments goes to the dataset\n",
    "    return all_assessments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_and_test(train, test):\n",
    "    compiled_train = []\n",
    "    compiled_test = []\n",
    "    for i, (ins_id, user_sample) in tqdm(enumerate(train.groupby('installation_id', sort = False)), total = 17000):\n",
    "        compiled_train += get_data(user_sample)\n",
    "    for ins_id, user_sample in tqdm(test.groupby('installation_id', sort = False), total = 1000):\n",
    "        test_data = get_data(user_sample, test_set = True)\n",
    "        compiled_test.append(test_data)\n",
    "    reduce_train = pd.DataFrame(compiled_train)\n",
    "    reduce_test = pd.DataFrame(compiled_test)\n",
    "    categoricals = ['session_title']\n",
    "    return reduce_train, reduce_test, categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base_Model(object):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True,ps={}):\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.features = features\n",
    "        self.n_splits = n_splits\n",
    "        self.categoricals = categoricals\n",
    "        self.target = 'accuracy_group'\n",
    "        self.cv = self.get_cv()\n",
    "        self.verbose = verbose\n",
    "#         self.params = self.get_params()\n",
    "        self.params = self.set_params(ps)\n",
    "        self.y_pred, self.score, self.model = self.fit()\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def get_cv(self):\n",
    "        cv = StratifiedKFold(n_splits=self.n_splits, shuffle=True, random_state=42)\n",
    "        return cv.split(self.train_df, self.train_df[self.target])\n",
    "    \n",
    "    def get_params(self):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def convert_x(self, x):\n",
    "        return x\n",
    "        \n",
    "    def fit(self):\n",
    "        oof_pred = np.zeros((len(reduce_train), ))\n",
    "        y_pred = np.zeros((len(reduce_test), ))\n",
    "        for fold, (train_idx, val_idx) in enumerate(self.cv):\n",
    "            x_train, x_val = self.train_df[self.features].iloc[train_idx], self.train_df[self.features].iloc[val_idx]\n",
    "            y_train, y_val = self.train_df[self.target][train_idx], self.train_df[self.target][val_idx]\n",
    "            train_set, val_set = self.convert_dataset(x_train, y_train, x_val, y_val)\n",
    "            model = self.train_model(train_set, val_set)\n",
    "            conv_x_val = self.convert_x(x_val)\n",
    "            oof_pred[val_idx] = model.predict(conv_x_val).reshape(oof_pred[val_idx].shape)\n",
    "            x_test = self.convert_x(self.test_df[self.features])\n",
    "            y_pred += model.predict(x_test).reshape(y_pred.shape) / self.n_splits\n",
    "            print('Partial score of fold {} is: {}'.format(fold, eval_qwk_lgb_regr(y_val, oof_pred[val_idx])[1]))\n",
    "        _, loss_score, _ = eval_qwk_lgb_regr(self.train_df[self.target], oof_pred)\n",
    "        if self.verbose:\n",
    "            print('Our oof cohen kappa score is: ', loss_score)\n",
    "        return y_pred, loss_score, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = lgb.Dataset(x_train, y_train, categorical_feature=self.categoricals)\n",
    "        val_set = lgb.Dataset(x_val, y_val, categorical_feature=self.categoricals)\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'n_estimators':5000,\n",
    "                    'boosting_type': 'gbdt',\n",
    "                    'objective': 'regression',\n",
    "                    'metric': 'rmse',\n",
    "                    'subsample': 0.75,\n",
    "                    'subsample_freq': 1,\n",
    "                    'learning_rate': 0.01,\n",
    "                    'feature_fraction': 0.9,\n",
    "                    'max_depth': 15,\n",
    "                    'lambda_l1': 1,  \n",
    "                    'lambda_l2': 1,\n",
    "                    'early_stopping_rounds': 100\n",
    "                    }\n",
    "        return params\n",
    "    def set_params(self,ps={}):\n",
    "        params = self.get_params()\n",
    "        if 'subsample_freq' in ps:\n",
    "            params['subsample_freq']=int(ps['subsample_freq'])\n",
    "            params['learning_rate']=ps['learning_rate']\n",
    "            params['feature_fraction']=ps['feature_fraction']\n",
    "            params['lambda_l1']=ps['lambda_l1']\n",
    "            params['lambda_l2']=ps['lambda_l2']\n",
    "            params['max_depth']=int(ps['max_depth'])\n",
    "        \n",
    "        return params    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Xgb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return lgb.train(self.params, train_set, valid_sets=[train_set, val_set], verbose_eval=verbosity)\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, ps={}):\n",
    "        return self.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class fuse_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        return xgb.train(self.params, train_set, \n",
    "                         num_boost_round=5000, evals=[(train_set, 'train'), (val_set, 'val')], \n",
    "                         verbose_eval=verbosity, early_stopping_rounds=100)\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = xgb.DMatrix(x_train, y_train)\n",
    "        val_set = xgb.DMatrix(x_val, y_val)\n",
    "        return train_set, val_set\n",
    "    \n",
    "    def convert_x(self, x):\n",
    "        return xgb.DMatrix(x)\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'colsample_bytree': 0.8,                 \n",
    "            'learning_rate': 0.01,\n",
    "            'max_depth': 10,\n",
    "            'subsample': 1,\n",
    "            'objective':'reg:squarederror',\n",
    "            #'eval_metric':'rmse',\n",
    "            'min_child_weight':3,\n",
    "            'gamma':0.25,\n",
    "            'n_estimators':5000}\n",
    "        return params\n",
    "    \n",
    "    def set_params(self, ps={}):\n",
    "        return self.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Catb_Model(Base_Model):\n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        clf = CatBoostRegressor(**self.params)\n",
    "        clf.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                eval_set=(val_set['X'], val_set['y']),\n",
    "                verbose=verbosity, \n",
    "                cat_features=self.categoricals)\n",
    "        return clf\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        params = {'loss_function': 'RMSE',\n",
    "                   'task_type': \"CPU\",\n",
    "                   'iterations': 5000,\n",
    "                   'od_type': \"Iter\",\n",
    "                    'depth': 10,\n",
    "                  'colsample_bylevel': 0.5, \n",
    "                   'early_stopping_rounds': 300,\n",
    "                    'l2_leaf_reg': 18,\n",
    "                   'random_seed': 42,\n",
    "                    'use_best_model': True\n",
    "                    }\n",
    "        return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder\n",
    "\n",
    "class Nn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        print(train_df[features].shape)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "        model = tf.keras.models.Sequential([\n",
    "            tf.keras.layers.Input(shape=(train_set['X'].shape[1],)),\n",
    "            tf.keras.layers.Dense(200, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(100, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(50, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(25, activation='relu'),\n",
    "            tf.keras.layers.LayerNormalization(),\n",
    "            tf.keras.layers.Dropout(0.3),\n",
    "            tf.keras.layers.Dense(1, activation='relu')\n",
    "        ])\n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=4e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice\n",
    "\n",
    "class Cnn_Model(Base_Model):\n",
    "    \n",
    "    def __init__(self, train_df, test_df, features, categoricals=[], n_splits=5, verbose=True):\n",
    "        features = features.copy()\n",
    "        if len(categoricals) > 0:\n",
    "            for cat in categoricals:\n",
    "                enc = OneHotEncoder()\n",
    "                train_cats = enc.fit_transform(train_df[[cat]])\n",
    "                test_cats = enc.transform(test_df[[cat]])\n",
    "                cat_cols = ['{}_{}'.format(cat, str(col)) for col in enc.active_features_]\n",
    "                features += cat_cols\n",
    "                train_cats = pd.DataFrame(train_cats.toarray(), columns=cat_cols)\n",
    "                test_cats = pd.DataFrame(test_cats.toarray(), columns=cat_cols)\n",
    "                train_df = pd.concat([train_df, train_cats], axis=1)\n",
    "                test_df = pd.concat([test_df, test_cats], axis=1)\n",
    "        scalar = MinMaxScaler()\n",
    "        train_df[features] = scalar.fit_transform(train_df[features])\n",
    "        test_df[features] = scalar.transform(test_df[features])\n",
    "        self.create_feat_2d(features)\n",
    "        super().__init__(train_df, test_df, features, categoricals, n_splits, verbose)\n",
    "        \n",
    "    def create_feat_2d(self, features, n_feats_repeat=50):\n",
    "        self.n_feats = len(features)\n",
    "        self.n_feats_repeat = n_feats_repeat\n",
    "        self.mask = np.zeros((self.n_feats_repeat, self.n_feats), dtype=np.int32)\n",
    "        for i in range(self.n_feats_repeat):\n",
    "            l = list(range(self.n_feats))\n",
    "            for j in range(self.n_feats):\n",
    "                c = l.pop(choice(range(len(l))))\n",
    "                self.mask[i, j] = c\n",
    "        self.mask = tf.convert_to_tensor(self.mask)\n",
    "        print(self.mask.shape)\n",
    "       \n",
    "        \n",
    "    \n",
    "    def train_model(self, train_set, val_set):\n",
    "        verbosity = 100 if self.verbose else 0\n",
    "\n",
    "        inp = tf.keras.layers.Input(shape=(self.n_feats))\n",
    "        x = tf.keras.layers.Lambda(lambda x: tf.gather(x, self.mask, axis=1))(inp)\n",
    "        x = tf.keras.layers.Reshape((self.n_feats_repeat, self.n_feats, 1))(x)\n",
    "        x = tf.keras.layers.Conv2D(18, (50, 50), strides=50, activation='relu')(x)\n",
    "        x = tf.keras.layers.Flatten()(x)\n",
    "        #x = tf.keras.layers.Dense(200, activation='relu')(x)\n",
    "        #x = tf.keras.layers.LayerNormalization()(x)\n",
    "        #x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(100, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        x = tf.keras.layers.Dense(50, activation='relu')(x)\n",
    "        x = tf.keras.layers.LayerNormalization()(x)\n",
    "        x = tf.keras.layers.Dropout(0.3)(x)\n",
    "        out = tf.keras.layers.Dense(1)(x)\n",
    "        \n",
    "        model = tf.keras.Model(inp, out)\n",
    "    \n",
    "        model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4), loss='mse')\n",
    "        print(model.summary())\n",
    "        save_best = tf.keras.callbacks.ModelCheckpoint('nn_model.w8', save_weights_only=True, save_best_only=True, verbose=1)\n",
    "        early_stop = tf.keras.callbacks.EarlyStopping(patience=20)\n",
    "        model.fit(train_set['X'], \n",
    "                train_set['y'], \n",
    "                validation_data=(val_set['X'], val_set['y']),\n",
    "                epochs=100,\n",
    "                 callbacks=[save_best, early_stop])\n",
    "        model.load_weights('nn_model.w8')\n",
    "        return model\n",
    "        \n",
    "    def convert_dataset(self, x_train, y_train, x_val, y_val):\n",
    "        train_set = {'X': x_train, 'y': y_train}\n",
    "        val_set = {'X': x_val, 'y': y_val}\n",
    "        return train_set, val_set\n",
    "        \n",
    "    def get_params(self):\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading train.csv file....\n",
      "Training.csv file have 11341042 rows and 11 columns\n",
      "Reading test.csv file....\n",
      "Test.csv file have 1156414 rows and 11 columns\n",
      "Reading train_labels.csv file....\n",
      "Train_labels.csv file have 17690 rows and 7 columns\n",
      "Reading specs.csv file....\n",
      "Specs.csv file have 386 rows and 3 columns\n",
      "Reading sample_submission.csv file....\n",
      "Sample_submission.csv file have 1000 rows and 2 columns\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17000/17000 [08:48<00:00, 32.17it/s]\n",
      "100%|██████████| 1000/1000 [00:57<00:00, 17.29it/s]\n"
     ]
    }
   ],
   "source": [
    "# read data\n",
    "train, test, train_labels, specs, sample_submission = read_data()\n",
    "# get usefull dict with maping encode\n",
    "train, test, train_labels, win_code, list_of_user_activities, list_of_event_code, activities_labels, assess_titles, list_of_event_id, all_title_event_code = encode_title(train, test, train_labels)\n",
    "# tranform function to get the train and test set\n",
    "reduce_train, reduce_test, categoricals = get_train_and_test(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0026939774600629332\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.0026939774600629332"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stract_hists(feature, train=reduce_train, test=reduce_test, adjust=False, plot=False):\n",
    "    n_bins = 10\n",
    "    train_data = train[feature]\n",
    "    test_data = test[feature]\n",
    "    if adjust:\n",
    "        test_data *= train_data.mean() / test_data.mean()\n",
    "    perc_90 = np.percentile(train_data, 95)\n",
    "    train_data = np.clip(train_data, 0, perc_90)\n",
    "    test_data = np.clip(test_data, 0, perc_90)\n",
    "    train_hist = np.histogram(train_data, bins=n_bins)[0] / len(train_data)\n",
    "    test_hist = np.histogram(test_data, bins=n_bins)[0] / len(test_data)\n",
    "    msre = mean_squared_error(train_hist, test_hist)\n",
    "    if plot:\n",
    "        print(msre)\n",
    "        plt.bar(range(n_bins), train_hist, color='blue', alpha=0.5)\n",
    "        plt.bar(range(n_bins), test_hist, color='red', alpha=0.5)\n",
    "        plt.show()\n",
    "    return msre\n",
    "stract_hists('Magma Peak - Level 1_2000', adjust=False, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call feature engineering function\n",
    "features = reduce_train.loc[(reduce_train.sum(axis=1) != 0), (reduce_train.sum(axis=0) != 0)].columns # delete useless columns\n",
    "features = [x for x in features if x not in ['accuracy_group', 'installation_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counter = 0\n",
    "# to_remove = []\n",
    "# for feat_a in features:\n",
    "#     for feat_b in features:\n",
    "#         if feat_a != feat_b and feat_a not in to_remove and feat_b not in to_remove:\n",
    "#             c = np.corrcoef(reduce_train[feat_a], reduce_train[feat_b])[0][1]\n",
    "#             if c > 0.995:\n",
    "#                 counter += 1\n",
    "#                 to_remove.append(feat_b)\n",
    "#                 print('{}: FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(counter, feat_a, feat_b, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_Cart Balancer (Assessment) -0.04020325710970116 -0.47065833333333346 0.006732930476733109\n",
      "7fd1ac25 0.01978518937252685 0.0\n",
      "ecc6157f 0.007292255511588468 0.0\n",
      "4074bac2 0.0 0.0\n",
      "119b5b02 0.0002826455624646693 0.0\n",
      "eb2c19cd 0.17382702091577162 0.008 0.0\n",
      "13f56524 0.04392312040700961 0.0\n",
      "6aeafed4 0.14703222159412097 0.008 0.0\n",
      "dcb1663e 0.0 0.0\n",
      "611485c5 0.0013566986998304127 0.0\n",
      "bfc77bd6 0.012832108535895986 0.0\n",
      "5dc079d8 0.0 0.0\n",
      "e4d32835 0.0013001695873374789 0.0\n",
      "ab4ec3a4 0.0009044657998869418 0.0\n",
      "0ce40006 0.0008479366873940079 0.0\n",
      "003cd2ee 0.0 0.0\n",
      "2ec694de 0.008988128886376484 0.0\n",
      "17ca3959 0.0 0.0\n",
      "29a42aea 0.004070096099491238 0.0\n",
      "01ca3a3c 0.0004522328999434709 0.0\n",
      "1b54d27f 0.0007348784624081402 0.0\n",
      "a8cc6fec 0.0 0.0\n",
      "5000_g 0.0 0.0\n",
      "5010_g 0.0 0.0\n",
      "4021_g 0.0 0.0\n",
      "4022_g 0.0 0.0\n",
      "2010_g 0.0 0.0\n",
      "2050_A 0.0 0.0\n",
      "4100_A 0.0 0.0\n",
      "4230_A 0.0 0.0\n",
      "4235_A 0.0 0.0\n",
      "2060_A 0.0 0.0\n",
      "4110_A 0.0 0.0\n",
      "2070_A 0.0 0.0\n",
      "2075_A 0.0 0.0\n",
      "2080_A 0.0 0.0\n",
      "2081_A 0.0 0.0\n",
      "2083_A 0.0 0.0\n",
      "4010_A 0.0 0.0\n",
      "3120_A 0.0 0.0\n",
      "3121_A 0.0 0.0\n",
      "4031_A 0.0 0.0\n",
      "4040_A 0.0 0.0\n",
      "3020_A 0.0 0.0\n",
      "3021_A 0.0 0.0\n",
      "4045_A 0.0 0.0\n",
      "4050_A 0.0 0.0\n",
      "2010_A 0.0007348784624081402 0.0\n",
      "2025_A 0.0 0.0\n",
      "2035_A 0.0 0.0\n",
      "2040_A 0.0 0.0\n",
      "4220_A 0.0 0.0\n",
      "4095_A 0.0 0.0\n",
      "Dino Dive_4080 0.0002826455624646693 0.0\n",
      "Air Show_4080 0.0 0.0\n",
      "Egg Dropper (Activity)_4080 0.01978518937252685 0.0\n",
      "Leaf Leader_4080 0.0004522328999434709 0.0\n",
      "Pan Balance_4080 0.0013001695873374789 0.0\n",
      "Sandcastle Builder (Activity)_2010 0.0 0.0\n",
      "Mushroom Sorter (Assessment)_4080 0.04392312040700961 0.0\n",
      "Crystals Rule_2010 0.0 0.0\n",
      "Fireworks (Activity)_4080 0.0013566986998304127 0.0\n",
      "Cart Balancer (Assessment)_4080 0.007292255511588468 0.0\n",
      "Scrub-A-Dub_4080 0.0 0.0\n",
      "Bottle Filler (Activity)_2010 0.0 0.0\n",
      "Mushroom Sorter (Assessment)_4090 0.17382702091577162 0.008 0.0\n",
      "Chest Sorter (Assessment)_4080 0.012832108535895986 0.0\n",
      "Bug Measurer (Activity)_4080 0.008988128886376484 0.0\n",
      "Happy Camel_4080 0.0008479366873940079 0.0\n",
      "Bubble Bath_4080 0.004070096099491238 0.0\n",
      "Bubble Bath_4090 0.14703222159412097 0.008 0.0\n",
      "Dino Drink_4080 0.0009044657998869418 0.0\n",
      "Pan Balance_2010 0.0 0.0\n",
      "Watering Hole (Activity)_2010 0.0007348784624081402 0.0\n"
     ]
    }
   ],
   "source": [
    "to_exclude = [] \n",
    "ajusted_test = reduce_test.copy()\n",
    "for feature in ajusted_test.columns:\n",
    "    if feature not in ['accuracy_group', 'installation_id', 'accuracy_group', 'session_title']:\n",
    "        data = reduce_train[feature]\n",
    "        train_mean = data.mean()\n",
    "        data = ajusted_test[feature] \n",
    "        test_mean = data.mean()\n",
    "        try:\n",
    "            error = stract_hists(feature, adjust=True)\n",
    "            ajust_factor = train_mean / test_mean\n",
    "            if ajust_factor > 10 or ajust_factor < 0.1:# or error > 0.01:\n",
    "                to_exclude.append(feature)\n",
    "                print(feature, train_mean, test_mean, error)\n",
    "            else:\n",
    "                ajusted_test[feature] *= ajust_factor\n",
    "        except:\n",
    "            to_exclude.append(feature)\n",
    "            print(feature, train_mean, test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'to_remove' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-447de8477246>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_exclude\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mto_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreduce_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-447de8477246>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mto_exclude\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mto_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mreduce_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'to_remove' is not defined"
     ]
    }
   ],
   "source": [
    "features = [x for x in features if x not in (to_exclude + to_remove)]\n",
    "reduce_train[features].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | featur... | lambda_l1 | lambda_l2 | learni... | max_depth | subsam... |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.631627\tvalid_1's rmse: 1.06031\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttraining's rmse: 0.883267\tvalid_1's rmse: 1.00721\n",
      "Partial score of fold 0 is: 0.5725855782184168\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.625159\tvalid_1's rmse: 1.06846\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.885383\tvalid_1's rmse: 1.01384\n",
      "Partial score of fold 1 is: 0.5732413609638183\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.630028\tvalid_1's rmse: 1.06249\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttraining's rmse: 0.92603\tvalid_1's rmse: 1.01007\n",
      "Partial score of fold 2 is: 0.5642946389714456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.631627\tvalid_1's rmse: 1.05796\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.888213\tvalid_1's rmse: 1.02058\n",
      "Partial score of fold 3 is: 0.5537375070204457\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.634007\tvalid_1's rmse: 1.08301\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's rmse: 0.908094\tvalid_1's rmse: 1.02196\n",
      "Partial score of fold 4 is: 0.5495181841548016\n",
      "Our oof cohen kappa score is:  0.5621866760052294\n",
      "kappa:  0.5621866760052294\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.5622  \u001b[0m | \u001b[0m 0.5205  \u001b[0m | \u001b[0m 2.049   \u001b[0m | \u001b[0m 2.944   \u001b[0m | \u001b[0m 0.4525  \u001b[0m | \u001b[0m 13.48   \u001b[0m | \u001b[0m 2.532   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.714709\tvalid_1's rmse: 1.00723\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttraining's rmse: 0.873248\tvalid_1's rmse: 0.983568\n",
      "Partial score of fold 0 is: 0.5904765125751177\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.712185\tvalid_1's rmse: 1.03422\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's rmse: 0.908726\tvalid_1's rmse: 1.0051\n",
      "Partial score of fold 1 is: 0.570736278805954\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.714015\tvalid_1's rmse: 1.02063\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's rmse: 0.892409\tvalid_1's rmse: 0.997443\n",
      "Partial score of fold 2 is: 0.5802198041178691\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.71333\tvalid_1's rmse: 1.00855\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's rmse: 0.894751\tvalid_1's rmse: 0.991015\n",
      "Partial score of fold 3 is: 0.5886297227906995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.717314\tvalid_1's rmse: 1.01462\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 0.889181\tvalid_1's rmse: 0.995936\n",
      "Partial score of fold 4 is: 0.5730538250578364\n",
      "Our oof cohen kappa score is:  0.5798560566475746\n",
      "kappa:  0.5798560566475746\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.5799  \u001b[0m | \u001b[95m 0.9701  \u001b[0m | \u001b[95m 2.977   \u001b[0m | \u001b[95m 1.678   \u001b[0m | \u001b[95m 0.2348  \u001b[0m | \u001b[95m 14.98   \u001b[0m | \u001b[95m 1.791   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.907529\tvalid_1's rmse: 0.985284\n",
      "[200]\ttraining's rmse: 0.839683\tvalid_1's rmse: 0.97854\n",
      "[300]\ttraining's rmse: 0.789665\tvalid_1's rmse: 0.979354\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's rmse: 0.81651\tvalid_1's rmse: 0.978018\n",
      "Partial score of fold 0 is: 0.5949492461642929\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.904047\tvalid_1's rmse: 0.99124\n",
      "[200]\ttraining's rmse: 0.837174\tvalid_1's rmse: 0.990073\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's rmse: 0.866758\tvalid_1's rmse: 0.988824\n",
      "Partial score of fold 1 is: 0.5893454605500893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.905748\tvalid_1's rmse: 0.991331\n",
      "[200]\ttraining's rmse: 0.838832\tvalid_1's rmse: 0.987582\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's rmse: 0.875701\tvalid_1's rmse: 0.986916\n",
      "Partial score of fold 2 is: 0.5879139850313098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.90874\tvalid_1's rmse: 0.995619\n",
      "[200]\ttraining's rmse: 0.840647\tvalid_1's rmse: 0.988411\n",
      "[300]\ttraining's rmse: 0.790979\tvalid_1's rmse: 0.989873\n",
      "Early stopping, best iteration is:\n",
      "[237]\ttraining's rmse: 0.821065\tvalid_1's rmse: 0.987414\n",
      "Partial score of fold 3 is: 0.5934609526665808\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.907926\tvalid_1's rmse: 0.987897\n",
      "[200]\ttraining's rmse: 0.841115\tvalid_1's rmse: 0.981182\n",
      "[300]\ttraining's rmse: 0.792014\tvalid_1's rmse: 0.98082\n",
      "[400]\ttraining's rmse: 0.75088\tvalid_1's rmse: 0.981563\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's rmse: 0.787254\tvalid_1's rmse: 0.980437\n",
      "Partial score of fold 4 is: 0.5912278058881342\n",
      "Our oof cohen kappa score is:  0.5907721400211575\n",
      "kappa:  0.5907721400211575\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.5908  \u001b[0m | \u001b[95m 0.6371  \u001b[0m | \u001b[95m 3.3     \u001b[0m | \u001b[95m 0.4016  \u001b[0m | \u001b[95m 0.04336 \u001b[0m | \u001b[95m 15.7    \u001b[0m | \u001b[95m 2.686   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.692906\tvalid_1's rmse: 1.01451\n",
      "Early stopping, best iteration is:\n",
      "[27]\ttraining's rmse: 0.867612\tvalid_1's rmse: 0.9874\n",
      "Partial score of fold 0 is: 0.595664883538561\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.694095\tvalid_1's rmse: 1.02547\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.904845\tvalid_1's rmse: 0.99894\n",
      "Partial score of fold 1 is: 0.5854089028734453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.696797\tvalid_1's rmse: 1.02654\n",
      "Early stopping, best iteration is:\n",
      "[16]\ttraining's rmse: 0.910027\tvalid_1's rmse: 1.00017\n",
      "Partial score of fold 2 is: 0.5768200497607674\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.692767\tvalid_1's rmse: 1.02708\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttraining's rmse: 0.932084\tvalid_1's rmse: 1.00378\n",
      "Partial score of fold 3 is: 0.5737781642833607\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.694301\tvalid_1's rmse: 1.02149\n",
      "Early stopping, best iteration is:\n",
      "[21]\ttraining's rmse: 0.891444\tvalid_1's rmse: 0.998493\n",
      "Partial score of fold 4 is: 0.5765488832180343\n",
      "Our oof cohen kappa score is:  0.581609788074806\n",
      "kappa:  0.581609788074806\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5816  \u001b[0m | \u001b[0m 0.9697  \u001b[0m | \u001b[0m 4.356   \u001b[0m | \u001b[0m 1.791   \u001b[0m | \u001b[0m 0.2947  \u001b[0m | \u001b[0m 16.52   \u001b[0m | \u001b[0m 5.072   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.77611\tvalid_1's rmse: 0.997122\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 0.893087\tvalid_1's rmse: 0.986799\n",
      "Partial score of fold 0 is: 0.5917288779800867\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.771383\tvalid_1's rmse: 1.00424\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's rmse: 0.877249\tvalid_1's rmse: 0.994062\n",
      "Partial score of fold 1 is: 0.5827248862757335\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.775414\tvalid_1's rmse: 1.00044\n",
      "Early stopping, best iteration is:\n",
      "[40]\ttraining's rmse: 0.877568\tvalid_1's rmse: 0.993925\n",
      "Partial score of fold 2 is: 0.5789672630389369\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.774122\tvalid_1's rmse: 1.0027\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.845886\tvalid_1's rmse: 0.996662\n",
      "Partial score of fold 3 is: 0.5857667717531403\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.777795\tvalid_1's rmse: 0.998091\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.895076\tvalid_1's rmse: 0.991509\n",
      "Partial score of fold 4 is: 0.5824562545364891\n",
      "Our oof cohen kappa score is:  0.5836140525630704\n",
      "kappa:  0.5836140525630704\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5836  \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m 3.981   \u001b[0m | \u001b[0m 4.719   \u001b[0m | \u001b[0m 0.1693  \u001b[0m | \u001b[0m 16.64   \u001b[0m | \u001b[0m 5.5     \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.770738\tvalid_1's rmse: 0.991177\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttraining's rmse: 0.867974\tvalid_1's rmse: 0.987352\n",
      "Partial score of fold 0 is: 0.5842146855502723\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.770607\tvalid_1's rmse: 1.01012\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.897987\tvalid_1's rmse: 0.995134\n",
      "Partial score of fold 1 is: 0.5820091485163437\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.77032\tvalid_1's rmse: 1.00729\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 0.858343\tvalid_1's rmse: 0.996664\n",
      "Partial score of fold 2 is: 0.5753885742419877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.768141\tvalid_1's rmse: 1.00669\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttraining's rmse: 0.822505\tvalid_1's rmse: 1.00249\n",
      "Partial score of fold 3 is: 0.5850510339937505\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.767863\tvalid_1's rmse: 1.00132\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's rmse: 0.857533\tvalid_1's rmse: 0.995343\n",
      "Partial score of fold 4 is: 0.5733266806806953\n",
      "Our oof cohen kappa score is:  0.5783886487186667\n",
      "kappa:  0.5783886487186667\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5784  \u001b[0m | \u001b[0m 0.5194  \u001b[0m | \u001b[0m 1.336   \u001b[0m | \u001b[0m 0.582   \u001b[0m | \u001b[0m 0.1599  \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 7.815   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.922438\tvalid_1's rmse: 0.982821\n",
      "[200]\ttraining's rmse: 0.860174\tvalid_1's rmse: 0.974415\n",
      "[300]\ttraining's rmse: 0.815155\tvalid_1's rmse: 0.975177\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's rmse: 0.859681\tvalid_1's rmse: 0.974359\n",
      "Partial score of fold 0 is: 0.5988852517227671\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.91828\tvalid_1's rmse: 0.992838\n",
      "[200]\ttraining's rmse: 0.85695\tvalid_1's rmse: 0.990181\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's rmse: 0.884058\tvalid_1's rmse: 0.989218\n",
      "Partial score of fold 1 is: 0.5823670173960386\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.920499\tvalid_1's rmse: 0.993979\n",
      "[200]\ttraining's rmse: 0.859104\tvalid_1's rmse: 0.987143\n",
      "[300]\ttraining's rmse: 0.813824\tvalid_1's rmse: 0.988865\n",
      "Early stopping, best iteration is:\n",
      "[200]\ttraining's rmse: 0.859104\tvalid_1's rmse: 0.987143\n",
      "Partial score of fold 2 is: 0.5913137393884114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.919502\tvalid_1's rmse: 0.994865\n",
      "[200]\ttraining's rmse: 0.858923\tvalid_1's rmse: 0.988395\n",
      "[300]\ttraining's rmse: 0.814482\tvalid_1's rmse: 0.987201\n",
      "[400]\ttraining's rmse: 0.778189\tvalid_1's rmse: 0.988686\n",
      "Early stopping, best iteration is:\n",
      "[304]\ttraining's rmse: 0.812898\tvalid_1's rmse: 0.987182\n",
      "Partial score of fold 3 is: 0.592387346027496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.920708\tvalid_1's rmse: 0.992453\n",
      "[200]\ttraining's rmse: 0.860336\tvalid_1's rmse: 0.984076\n",
      "[300]\ttraining's rmse: 0.815962\tvalid_1's rmse: 0.981561\n",
      "[400]\ttraining's rmse: 0.778982\tvalid_1's rmse: 0.981581\n",
      "Early stopping, best iteration is:\n",
      "[333]\ttraining's rmse: 0.803249\tvalid_1's rmse: 0.98064\n",
      "Partial score of fold 4 is: 0.5858574683259025\n",
      "Our oof cohen kappa score is:  0.5906289782719958\n",
      "kappa:  0.5906289782719958\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.5906  \u001b[0m | \u001b[0m 0.8534  \u001b[0m | \u001b[0m 2.64    \u001b[0m | \u001b[0m 4.351   \u001b[0m | \u001b[0m 0.03592 \u001b[0m | \u001b[0m 14.23   \u001b[0m | \u001b[0m 2.515   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.778103\tvalid_1's rmse: 0.996439\n",
      "Early stopping, best iteration is:\n",
      "[42]\ttraining's rmse: 0.875977\tvalid_1's rmse: 0.988451\n",
      "Partial score of fold 0 is: 0.5883296004523135\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.77652\tvalid_1's rmse: 1.0071\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 0.883814\tvalid_1's rmse: 0.993457\n",
      "Partial score of fold 1 is: 0.584514230674208\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.778643\tvalid_1's rmse: 1.00106\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's rmse: 0.901142\tvalid_1's rmse: 0.99076\n",
      "Partial score of fold 2 is: 0.5809355418772589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.777288\tvalid_1's rmse: 0.997471\n",
      "Early stopping, best iteration is:\n",
      "[80]\ttraining's rmse: 0.805531\tvalid_1's rmse: 0.995709\n",
      "Partial score of fold 3 is: 0.5879139850313098\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.776641\tvalid_1's rmse: 0.998154\n",
      "Early stopping, best iteration is:\n",
      "[54]\ttraining's rmse: 0.853434\tvalid_1's rmse: 0.989808\n",
      "Partial score of fold 4 is: 0.5835303220489354\n",
      "Our oof cohen kappa score is:  0.5841509091224268\n",
      "kappa:  0.5841509091224268\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.5842  \u001b[0m | \u001b[0m 0.713   \u001b[0m | \u001b[0m 3.884   \u001b[0m | \u001b[0m 2.672   \u001b[0m | \u001b[0m 0.1635  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 7.059   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.748203\tvalid_1's rmse: 0.994169\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's rmse: 0.897192\tvalid_1's rmse: 0.984604\n",
      "Partial score of fold 0 is: 0.5902976032315507\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.749455\tvalid_1's rmse: 1.01324\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.879363\tvalid_1's rmse: 0.99786\n",
      "Partial score of fold 1 is: 0.5803987385577165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.751601\tvalid_1's rmse: 1.00391\n",
      "Early stopping, best iteration is:\n",
      "[31]\ttraining's rmse: 0.886534\tvalid_1's rmse: 0.992536\n",
      "Partial score of fold 2 is: 0.5877350505914622\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.747803\tvalid_1's rmse: 1.01401\n",
      "Early stopping, best iteration is:\n",
      "[51]\ttraining's rmse: 0.836455\tvalid_1's rmse: 1.00723\n",
      "Partial score of fold 3 is: 0.5719888198848861\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.75389\tvalid_1's rmse: 1.011\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 0.881501\tvalid_1's rmse: 0.997345\n",
      "Partial score of fold 4 is: 0.5715365681599514\n",
      "Our oof cohen kappa score is:  0.5798375777539971\n",
      "kappa:  0.5798375777539971\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.5798  \u001b[0m | \u001b[0m 0.6277  \u001b[0m | \u001b[0m 3.202   \u001b[0m | \u001b[0m 3.754   \u001b[0m | \u001b[0m 0.2022  \u001b[0m | \u001b[0m 13.63   \u001b[0m | \u001b[0m 9.341   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.761858\tvalid_1's rmse: 0.993481\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.887184\tvalid_1's rmse: 0.98169\n",
      "Partial score of fold 0 is: 0.5938757901028908\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.754779\tvalid_1's rmse: 1.0137\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttraining's rmse: 0.906388\tvalid_1's rmse: 0.995777\n",
      "Partial score of fold 1 is: 0.5793251319186319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.760357\tvalid_1's rmse: 1.00064\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 0.875094\tvalid_1's rmse: 0.99061\n",
      "Partial score of fold 2 is: 0.5864825095125301\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.751868\tvalid_1's rmse: 1.00345\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's rmse: 0.875345\tvalid_1's rmse: 0.996658\n",
      "Partial score of fold 3 is: 0.5795040663584793\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.759402\tvalid_1's rmse: 1.00575\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttraining's rmse: 0.873961\tvalid_1's rmse: 0.995847\n",
      "Partial score of fold 4 is: 0.5803081195115964\n",
      "Our oof cohen kappa score is:  0.5829340342545521\n",
      "kappa:  0.5829340342545521\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.5829  \u001b[0m | \u001b[0m 0.9993  \u001b[0m | \u001b[0m 0.5259  \u001b[0m | \u001b[0m 4.569   \u001b[0m | \u001b[0m 0.1726  \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 9.381   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.604097\tvalid_1's rmse: 1.06276\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's rmse: 0.941033\tvalid_1's rmse: 1.00284\n",
      "Partial score of fold 0 is: 0.5737867742054814\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.608064\tvalid_1's rmse: 1.08549\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's rmse: 0.938646\tvalid_1's rmse: 1.0137\n",
      "Partial score of fold 1 is: 0.5617895568135811\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.612532\tvalid_1's rmse: 1.09314\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttraining's rmse: 0.925521\tvalid_1's rmse: 1.01228\n",
      "Partial score of fold 2 is: 0.5674509488527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.604161\tvalid_1's rmse: 1.07639\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's rmse: 0.941568\tvalid_1's rmse: 1.01574\n",
      "Partial score of fold 3 is: 0.5676943933285472\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.605755\tvalid_1's rmse: 1.07019\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's rmse: 0.899685\tvalid_1's rmse: 1.00838\n",
      "Partial score of fold 4 is: 0.569567444387133\n",
      "Our oof cohen kappa score is:  0.5678030704115861\n",
      "kappa:  0.5678030704115861\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.5678  \u001b[0m | \u001b[0m 0.9364  \u001b[0m | \u001b[0m 0.2751  \u001b[0m | \u001b[0m 4.832   \u001b[0m | \u001b[0m 0.4788  \u001b[0m | \u001b[0m 13.28   \u001b[0m | \u001b[0m 5.325   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.773708\tvalid_1's rmse: 0.986797\n",
      "Early stopping, best iteration is:\n",
      "[52]\ttraining's rmse: 0.855314\tvalid_1's rmse: 0.981266\n",
      "Partial score of fold 0 is: 0.5945914274771589\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.769412\tvalid_1's rmse: 1.01407\n",
      "Early stopping, best iteration is:\n",
      "[28]\ttraining's rmse: 0.906183\tvalid_1's rmse: 1.0016\n",
      "Partial score of fold 1 is: 0.5731474960083734\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.774959\tvalid_1's rmse: 1.00643\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 0.891189\tvalid_1's rmse: 0.994715\n",
      "Partial score of fold 2 is: 0.5873771817117673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.771722\tvalid_1's rmse: 1.00285\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 0.86276\tvalid_1's rmse: 0.996114\n",
      "Partial score of fold 3 is: 0.5836195584749708\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.772126\tvalid_1's rmse: 1.00025\n",
      "Early stopping, best iteration is:\n",
      "[41]\ttraining's rmse: 0.875199\tvalid_1's rmse: 0.989938\n",
      "Partial score of fold 4 is: 0.5829932882927122\n",
      "Our oof cohen kappa score is:  0.5838287951868131\n",
      "kappa:  0.5838287951868131\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.5838  \u001b[0m | \u001b[0m 0.755   \u001b[0m | \u001b[0m 1.843   \u001b[0m | \u001b[0m 2.172   \u001b[0m | \u001b[0m 0.1569  \u001b[0m | \u001b[0m 14.26   \u001b[0m | \u001b[0m 6.525   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.694551\tvalid_1's rmse: 1.01935\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 0.896521\tvalid_1's rmse: 0.989904\n",
      "Partial score of fold 0 is: 0.5851969019777246\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.691642\tvalid_1's rmse: 1.03007\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.906369\tvalid_1's rmse: 1.00577\n",
      "Partial score of fold 1 is: 0.5714520165653438\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.695352\tvalid_1's rmse: 1.03508\n",
      "Early stopping, best iteration is:\n",
      "[17]\ttraining's rmse: 0.912954\tvalid_1's rmse: 1.0034\n",
      "Partial score of fold 2 is: 0.572704557644276\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.689562\tvalid_1's rmse: 1.02305\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's rmse: 0.883927\tvalid_1's rmse: 1.00981\n",
      "Partial score of fold 3 is: 0.5700205410465642\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.692827\tvalid_1's rmse: 1.03325\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttraining's rmse: 0.89031\tvalid_1's rmse: 1.00136\n",
      "Partial score of fold 4 is: 0.5747587706972903\n",
      "Our oof cohen kappa score is:  0.574881185864204\n",
      "kappa:  0.574881185864204\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.5749  \u001b[0m | \u001b[0m 0.6994  \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 3.371   \u001b[0m | \u001b[0m 0.2804  \u001b[0m | \u001b[0m 16.8    \u001b[0m | \u001b[0m 5.218   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.748298\tvalid_1's rmse: 0.996034\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's rmse: 0.885586\tvalid_1's rmse: 0.984563\n",
      "Partial score of fold 0 is: 0.5922656060107878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.746104\tvalid_1's rmse: 1.02122\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's rmse: 0.879874\tvalid_1's rmse: 1.0067\n",
      "Partial score of fold 1 is: 0.5757464431216828\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.748174\tvalid_1's rmse: 1.00458\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's rmse: 0.910458\tvalid_1's rmse: 0.995781\n",
      "Partial score of fold 2 is: 0.5819172120232958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.748623\tvalid_1's rmse: 1.0097\n",
      "Early stopping, best iteration is:\n",
      "[36]\ttraining's rmse: 0.876884\tvalid_1's rmse: 1.0018\n",
      "Partial score of fold 3 is: 0.5814723451968014\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.75113\tvalid_1's rmse: 1.00172\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttraining's rmse: 0.849662\tvalid_1's rmse: 0.995872\n",
      "Partial score of fold 4 is: 0.5797710857553733\n",
      "Our oof cohen kappa score is:  0.5804287036442216\n",
      "kappa:  0.5804287036442216\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.5804  \u001b[0m | \u001b[0m 0.6269  \u001b[0m | \u001b[0m 0.9706  \u001b[0m | \u001b[0m 4.516   \u001b[0m | \u001b[0m 0.1912  \u001b[0m | \u001b[0m 15.71   \u001b[0m | \u001b[0m 5.414   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.773824\tvalid_1's rmse: 0.993862\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttraining's rmse: 0.887447\tvalid_1's rmse: 0.985689\n",
      "Partial score of fold 0 is: 0.5867194163602105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.770039\tvalid_1's rmse: 1.00179\n",
      "Early stopping, best iteration is:\n",
      "[34]\ttraining's rmse: 0.890271\tvalid_1's rmse: 0.989005\n",
      "Partial score of fold 1 is: 0.5916716082681062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.771087\tvalid_1's rmse: 0.999326\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttraining's rmse: 0.870767\tvalid_1's rmse: 0.989778\n",
      "Partial score of fold 2 is: 0.5861246406328351\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.771804\tvalid_1's rmse: 1.00015\n",
      "Early stopping, best iteration is:\n",
      "[32]\ttraining's rmse: 0.896542\tvalid_1's rmse: 0.996114\n",
      "Partial score of fold 3 is: 0.5859457061929877\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.774776\tvalid_1's rmse: 1.00068\n",
      "Early stopping, best iteration is:\n",
      "[49]\ttraining's rmse: 0.860137\tvalid_1's rmse: 0.993799\n",
      "Partial score of fold 4 is: 0.5829932882927122\n",
      "Our oof cohen kappa score is:  0.5865488684208862\n",
      "kappa:  0.5865488684208862\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.5865  \u001b[0m | \u001b[0m 0.853   \u001b[0m | \u001b[0m 1.536   \u001b[0m | \u001b[0m 0.4828  \u001b[0m | \u001b[0m 0.1487  \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 7.365   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.680972\tvalid_1's rmse: 1.02053\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's rmse: 0.873839\tvalid_1's rmse: 1.00045\n",
      "Partial score of fold 0 is: 0.577237221151159\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.682633\tvalid_1's rmse: 1.03755\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttraining's rmse: 0.877577\tvalid_1's rmse: 1.00637\n",
      "Partial score of fold 1 is: 0.5710941476856488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.682422\tvalid_1's rmse: 1.03738\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttraining's rmse: 0.892989\tvalid_1's rmse: 1.00306\n",
      "Partial score of fold 2 is: 0.5743149676029031\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.682246\tvalid_1's rmse: 1.03678\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttraining's rmse: 0.869316\tvalid_1's rmse: 1.01255\n",
      "Partial score of fold 3 is: 0.5784304597193946\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.681192\tvalid_1's rmse: 1.03461\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttraining's rmse: 0.883725\tvalid_1's rmse: 1.00764\n",
      "Partial score of fold 4 is: 0.5683143656226124\n",
      "Our oof cohen kappa score is:  0.5733421970607153\n",
      "kappa:  0.5733421970607153\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.5733  \u001b[0m | \u001b[0m 0.6327  \u001b[0m | \u001b[0m 1.826   \u001b[0m | \u001b[0m 1.33    \u001b[0m | \u001b[0m 0.2994  \u001b[0m | \u001b[0m 14.77   \u001b[0m | \u001b[0m 7.747   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.947091\tvalid_1's rmse: 0.993111\n",
      "[200]\ttraining's rmse: 0.890001\tvalid_1's rmse: 0.977571\n",
      "[300]\ttraining's rmse: 0.851601\tvalid_1's rmse: 0.97603\n",
      "[400]\ttraining's rmse: 0.818816\tvalid_1's rmse: 0.975469\n",
      "Early stopping, best iteration is:\n",
      "[393]\ttraining's rmse: 0.820929\tvalid_1's rmse: 0.975152\n",
      "Partial score of fold 0 is: 0.6026423479376742\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.943138\tvalid_1's rmse: 1.00093\n",
      "[200]\ttraining's rmse: 0.8868\tvalid_1's rmse: 0.993121\n",
      "Early stopping, best iteration is:\n",
      "[190]\ttraining's rmse: 0.891007\tvalid_1's rmse: 0.992486\n",
      "Partial score of fold 1 is: 0.5830827551554284\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.944802\tvalid_1's rmse: 0.999174\n",
      "[200]\ttraining's rmse: 0.888106\tvalid_1's rmse: 0.987002\n",
      "[300]\ttraining's rmse: 0.849487\tvalid_1's rmse: 0.985664\n",
      "Early stopping, best iteration is:\n",
      "[297]\ttraining's rmse: 0.850662\tvalid_1's rmse: 0.985563\n",
      "Partial score of fold 2 is: 0.594355624865818\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.943274\tvalid_1's rmse: 0.99832\n",
      "[200]\ttraining's rmse: 0.887517\tvalid_1's rmse: 0.987826\n",
      "[300]\ttraining's rmse: 0.849438\tvalid_1's rmse: 0.98671\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's rmse: 0.856873\tvalid_1's rmse: 0.986326\n",
      "Partial score of fold 3 is: 0.5895243949899367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.944792\tvalid_1's rmse: 1.00425\n",
      "[200]\ttraining's rmse: 0.887923\tvalid_1's rmse: 0.988797\n",
      "[300]\ttraining's rmse: 0.849913\tvalid_1's rmse: 0.986389\n",
      "[400]\ttraining's rmse: 0.818334\tvalid_1's rmse: 0.986278\n",
      "Early stopping, best iteration is:\n",
      "[366]\ttraining's rmse: 0.828371\tvalid_1's rmse: 0.985506\n",
      "Partial score of fold 4 is: 0.583351310796861\n",
      "Our oof cohen kappa score is:  0.5911658348313523\n",
      "kappa:  0.5911658348313523\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.5912  \u001b[0m | \u001b[95m 0.9015  \u001b[0m | \u001b[95m 4.438   \u001b[0m | \u001b[95m 0.3126  \u001b[0m | \u001b[95m 0.02662 \u001b[0m | \u001b[95m 13.32   \u001b[0m | \u001b[95m 8.676   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.905189\tvalid_1's rmse: 0.980619\n",
      "[200]\ttraining's rmse: 0.84103\tvalid_1's rmse: 0.978946\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.890669\tvalid_1's rmse: 0.977564\n",
      "Partial score of fold 0 is: 0.5944125181335919\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.900664\tvalid_1's rmse: 0.990815\n",
      "[200]\ttraining's rmse: 0.837577\tvalid_1's rmse: 0.992008\n",
      "Early stopping, best iteration is:\n",
      "[137]\ttraining's rmse: 0.874445\tvalid_1's rmse: 0.990074\n",
      "Partial score of fold 1 is: 0.5870193128320724\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.90265\tvalid_1's rmse: 0.988567\n",
      "[200]\ttraining's rmse: 0.83975\tvalid_1's rmse: 0.986348\n",
      "Early stopping, best iteration is:\n",
      "[194]\ttraining's rmse: 0.843111\tvalid_1's rmse: 0.986135\n",
      "Partial score of fold 2 is: 0.5909558705087163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.902304\tvalid_1's rmse: 0.988454\n",
      "[200]\ttraining's rmse: 0.838324\tvalid_1's rmse: 0.985724\n",
      "[300]\ttraining's rmse: 0.791632\tvalid_1's rmse: 0.986847\n",
      "Early stopping, best iteration is:\n",
      "[207]\ttraining's rmse: 0.834965\tvalid_1's rmse: 0.985574\n",
      "Partial score of fold 3 is: 0.5909558705087163\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.904303\tvalid_1's rmse: 0.989022\n",
      "[200]\ttraining's rmse: 0.840921\tvalid_1's rmse: 0.983223\n",
      "[300]\ttraining's rmse: 0.793115\tvalid_1's rmse: 0.983183\n",
      "[400]\ttraining's rmse: 0.753239\tvalid_1's rmse: 0.983945\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.78117\tvalid_1's rmse: 0.981814\n",
      "Partial score of fold 4 is: 0.5851414233176049\n",
      "Our oof cohen kappa score is:  0.5889826181566358\n",
      "kappa:  0.5889826181566358\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.589   \u001b[0m | \u001b[0m 0.9493  \u001b[0m | \u001b[0m 4.892   \u001b[0m | \u001b[0m 4.065   \u001b[0m | \u001b[0m 0.04653 \u001b[0m | \u001b[0m 13.21   \u001b[0m | \u001b[0m 3.626   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.859001\tvalid_1's rmse: 0.97717\n",
      "[200]\ttraining's rmse: 0.772291\tvalid_1's rmse: 0.979195\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's rmse: 0.856995\tvalid_1's rmse: 0.976788\n",
      "Partial score of fold 0 is: 0.596738339599963\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.853853\tvalid_1's rmse: 0.990629\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's rmse: 0.864979\tvalid_1's rmse: 0.990487\n",
      "Partial score of fold 1 is: 0.5803987385577165\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.855818\tvalid_1's rmse: 0.987999\n",
      "Early stopping, best iteration is:\n",
      "[74]\ttraining's rmse: 0.884661\tvalid_1's rmse: 0.987011\n",
      "Partial score of fold 2 is: 0.5920294771478012\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.857537\tvalid_1's rmse: 0.991839\n",
      "[200]\ttraining's rmse: 0.772504\tvalid_1's rmse: 0.993773\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's rmse: 0.846659\tvalid_1's rmse: 0.9915\n",
      "Partial score of fold 3 is: 0.5900611983094791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.858504\tvalid_1's rmse: 0.98892\n",
      "[200]\ttraining's rmse: 0.773567\tvalid_1's rmse: 0.989479\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's rmse: 0.839319\tvalid_1's rmse: 0.988569\n",
      "Partial score of fold 4 is: 0.5776229507304806\n",
      "Our oof cohen kappa score is:  0.5888036659701836\n",
      "kappa:  0.5888036659701836\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.5888  \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 0.06899 \u001b[0m | \u001b[0m 0.3895  \u001b[0m | \u001b[0m 0.06658 \u001b[0m | \u001b[0m 16.19   \u001b[0m | \u001b[0m 2.721   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.927527\tvalid_1's rmse: 0.985576\n",
      "[200]\ttraining's rmse: 0.867517\tvalid_1's rmse: 0.976917\n",
      "[300]\ttraining's rmse: 0.82408\tvalid_1's rmse: 0.977262\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's rmse: 0.862989\tvalid_1's rmse: 0.976683\n",
      "Partial score of fold 0 is: 0.5997797984406021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.924188\tvalid_1's rmse: 0.99389\n",
      "[200]\ttraining's rmse: 0.864314\tvalid_1's rmse: 0.991507\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttraining's rmse: 0.890451\tvalid_1's rmse: 0.990813\n",
      "Partial score of fold 1 is: 0.5882718539110046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.924873\tvalid_1's rmse: 0.990464\n",
      "[200]\ttraining's rmse: 0.865\tvalid_1's rmse: 0.984612\n",
      "Early stopping, best iteration is:\n",
      "[168]\ttraining's rmse: 0.88134\tvalid_1's rmse: 0.984154\n",
      "Partial score of fold 2 is: 0.5913137393884114\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.923959\tvalid_1's rmse: 0.996042\n",
      "[200]\ttraining's rmse: 0.864033\tvalid_1's rmse: 0.990804\n",
      "[300]\ttraining's rmse: 0.820486\tvalid_1's rmse: 0.991557\n",
      "Early stopping, best iteration is:\n",
      "[224]\ttraining's rmse: 0.853163\tvalid_1's rmse: 0.989979\n",
      "Partial score of fold 3 is: 0.5900611983094791\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925872\tvalid_1's rmse: 0.9959\n",
      "[200]\ttraining's rmse: 0.865919\tvalid_1's rmse: 0.987027\n",
      "[300]\ttraining's rmse: 0.822985\tvalid_1's rmse: 0.987398\n",
      "Early stopping, best iteration is:\n",
      "[244]\ttraining's rmse: 0.845168\tvalid_1's rmse: 0.986407\n",
      "Partial score of fold 4 is: 0.5826352657885634\n",
      "Our oof cohen kappa score is:  0.589412103404121\n",
      "kappa:  0.589412103404121\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.5894  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 4.019   \u001b[0m | \u001b[0m 0.03026 \u001b[0m | \u001b[0m 0.03373 \u001b[0m | \u001b[0m 16.99   \u001b[0m | \u001b[0m 7.046   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.894304\tvalid_1's rmse: 0.981292\n",
      "[200]\ttraining's rmse: 0.826373\tvalid_1's rmse: 0.977446\n",
      "Early stopping, best iteration is:\n",
      "[197]\ttraining's rmse: 0.828217\tvalid_1's rmse: 0.976944\n",
      "Partial score of fold 0 is: 0.5990641610663341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.890066\tvalid_1's rmse: 0.990126\n",
      "[200]\ttraining's rmse: 0.822138\tvalid_1's rmse: 0.989824\n",
      "Early stopping, best iteration is:\n",
      "[142]\ttraining's rmse: 0.858731\tvalid_1's rmse: 0.988632\n",
      "Partial score of fold 1 is: 0.5875561161516147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.892709\tvalid_1's rmse: 0.988077\n",
      "[200]\ttraining's rmse: 0.825141\tvalid_1's rmse: 0.988172\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttraining's rmse: 0.863055\tvalid_1's rmse: 0.987173\n",
      "Partial score of fold 2 is: 0.5898822638696317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.89292\tvalid_1's rmse: 0.990369\n",
      "[200]\ttraining's rmse: 0.824438\tvalid_1's rmse: 0.988851\n",
      "Early stopping, best iteration is:\n",
      "[174]\ttraining's rmse: 0.839804\tvalid_1's rmse: 0.988401\n",
      "Partial score of fold 3 is: 0.5916716082681062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.893567\tvalid_1's rmse: 0.98702\n",
      "[200]\ttraining's rmse: 0.825146\tvalid_1's rmse: 0.980954\n",
      "[300]\ttraining's rmse: 0.774432\tvalid_1's rmse: 0.982774\n",
      "Early stopping, best iteration is:\n",
      "[220]\ttraining's rmse: 0.814338\tvalid_1's rmse: 0.980442\n",
      "Partial score of fold 4 is: 0.5908697833839853\n",
      "Our oof cohen kappa score is:  0.5906647687092863\n",
      "kappa:  0.5906647687092863\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.5907  \u001b[0m | \u001b[0m 0.7948  \u001b[0m | \u001b[0m 4.649   \u001b[0m | \u001b[0m 3.404   \u001b[0m | \u001b[0m 0.05252 \u001b[0m | \u001b[0m 16.95   \u001b[0m | \u001b[0m 1.066   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.946471\tvalid_1's rmse: 0.992376\n",
      "[200]\ttraining's rmse: 0.889795\tvalid_1's rmse: 0.977185\n",
      "[300]\ttraining's rmse: 0.851252\tvalid_1's rmse: 0.97635\n",
      "[400]\ttraining's rmse: 0.818665\tvalid_1's rmse: 0.975597\n",
      "[500]\ttraining's rmse: 0.79105\tvalid_1's rmse: 0.976283\n",
      "Early stopping, best iteration is:\n",
      "[403]\ttraining's rmse: 0.817809\tvalid_1's rmse: 0.975382\n",
      "Partial score of fold 0 is: 0.6006743451584371\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.942769\tvalid_1's rmse: 0.99767\n",
      "[200]\ttraining's rmse: 0.886374\tvalid_1's rmse: 0.988677\n",
      "[300]\ttraining's rmse: 0.847405\tvalid_1's rmse: 0.98828\n",
      "[400]\ttraining's rmse: 0.814509\tvalid_1's rmse: 0.988326\n",
      "Early stopping, best iteration is:\n",
      "[336]\ttraining's rmse: 0.835317\tvalid_1's rmse: 0.987716\n",
      "Partial score of fold 1 is: 0.5882718539110046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.945129\tvalid_1's rmse: 1.00006\n",
      "[200]\ttraining's rmse: 0.887636\tvalid_1's rmse: 0.987867\n",
      "[300]\ttraining's rmse: 0.849181\tvalid_1's rmse: 0.986131\n",
      "[400]\ttraining's rmse: 0.817492\tvalid_1's rmse: 0.986728\n",
      "Early stopping, best iteration is:\n",
      "[334]\ttraining's rmse: 0.837622\tvalid_1's rmse: 0.985866\n",
      "Partial score of fold 2 is: 0.5839774273546656\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.943891\tvalid_1's rmse: 1.00124\n",
      "[200]\ttraining's rmse: 0.887733\tvalid_1's rmse: 0.990105\n",
      "[300]\ttraining's rmse: 0.849356\tvalid_1's rmse: 0.988489\n",
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's rmse: 0.864873\tvalid_1's rmse: 0.988125\n",
      "Partial score of fold 3 is: 0.5875561161516147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.944841\tvalid_1's rmse: 1.00066\n",
      "[200]\ttraining's rmse: 0.888767\tvalid_1's rmse: 0.984528\n",
      "[300]\ttraining's rmse: 0.850899\tvalid_1's rmse: 0.982081\n",
      "[400]\ttraining's rmse: 0.818792\tvalid_1's rmse: 0.98124\n",
      "Early stopping, best iteration is:\n",
      "[398]\ttraining's rmse: 0.819344\tvalid_1's rmse: 0.98112\n",
      "Partial score of fold 4 is: 0.588900659611167\n",
      "Our oof cohen kappa score is:  0.5904142356482531\n",
      "kappa:  0.5904142356482531\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.5904  \u001b[0m | \u001b[0m 0.9846  \u001b[0m | \u001b[0m 4.233   \u001b[0m | \u001b[0m 0.2935  \u001b[0m | \u001b[0m 0.02601 \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 2.76    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.94509\tvalid_1's rmse: 0.992238\n",
      "[200]\ttraining's rmse: 0.886984\tvalid_1's rmse: 0.979466\n",
      "[300]\ttraining's rmse: 0.847767\tvalid_1's rmse: 0.979877\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's rmse: 0.86623\tvalid_1's rmse: 0.978771\n",
      "Partial score of fold 0 is: 0.598348523692066\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.942229\tvalid_1's rmse: 0.997816\n",
      "[200]\ttraining's rmse: 0.883266\tvalid_1's rmse: 0.990656\n",
      "[300]\ttraining's rmse: 0.84356\tvalid_1's rmse: 0.990072\n",
      "[400]\ttraining's rmse: 0.810241\tvalid_1's rmse: 0.993022\n",
      "Early stopping, best iteration is:\n",
      "[308]\ttraining's rmse: 0.840692\tvalid_1's rmse: 0.989745\n",
      "Partial score of fold 1 is: 0.5871982472719199\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.944698\tvalid_1's rmse: 1.00127\n",
      "[200]\ttraining's rmse: 0.887199\tvalid_1's rmse: 0.989448\n",
      "[300]\ttraining's rmse: 0.846709\tvalid_1's rmse: 0.988643\n",
      "Early stopping, best iteration is:\n",
      "[263]\ttraining's rmse: 0.861156\tvalid_1's rmse: 0.987851\n",
      "Partial score of fold 2 is: 0.5854089028734453\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.94126\tvalid_1's rmse: 1.00006\n",
      "[200]\ttraining's rmse: 0.883929\tvalid_1's rmse: 0.98786\n",
      "[300]\ttraining's rmse: 0.846002\tvalid_1's rmse: 0.985797\n",
      "Early stopping, best iteration is:\n",
      "[280]\ttraining's rmse: 0.852777\tvalid_1's rmse: 0.985662\n",
      "Partial score of fold 3 is: 0.5961449692642926\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.943589\tvalid_1's rmse: 1.00253\n",
      "[200]\ttraining's rmse: 0.886114\tvalid_1's rmse: 0.98992\n",
      "[300]\ttraining's rmse: 0.84767\tvalid_1's rmse: 0.988107\n",
      "[400]\ttraining's rmse: 0.815911\tvalid_1's rmse: 0.988803\n",
      "Early stopping, best iteration is:\n",
      "[337]\ttraining's rmse: 0.835364\tvalid_1's rmse: 0.987852\n",
      "Partial score of fold 4 is: 0.5785180069908525\n",
      "Our oof cohen kappa score is:  0.5896984269024445\n",
      "kappa:  0.5896984269024445\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.5897  \u001b[0m | \u001b[0m 0.9926  \u001b[0m | \u001b[0m 1.298   \u001b[0m | \u001b[0m 2.178   \u001b[0m | \u001b[0m 0.02594 \u001b[0m | \u001b[0m 13.19   \u001b[0m | \u001b[0m 9.524   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.890856\tvalid_1's rmse: 0.978474\n",
      "[200]\ttraining's rmse: 0.821596\tvalid_1's rmse: 0.979366\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's rmse: 0.883437\tvalid_1's rmse: 0.976965\n",
      "Partial score of fold 0 is: 0.5962016115692619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.888467\tvalid_1's rmse: 0.990367\n",
      "[200]\ttraining's rmse: 0.82048\tvalid_1's rmse: 0.993114\n",
      "Early stopping, best iteration is:\n",
      "[117]\ttraining's rmse: 0.874574\tvalid_1's rmse: 0.989489\n",
      "Partial score of fold 1 is: 0.5882718539110046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.890124\tvalid_1's rmse: 0.992414\n",
      "[200]\ttraining's rmse: 0.822014\tvalid_1's rmse: 0.990124\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's rmse: 0.851125\tvalid_1's rmse: 0.989712\n",
      "Partial score of fold 2 is: 0.5895243949899367\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.889323\tvalid_1's rmse: 0.992216\n",
      "[200]\ttraining's rmse: 0.82168\tvalid_1's rmse: 0.993879\n",
      "Early stopping, best iteration is:\n",
      "[100]\ttraining's rmse: 0.889323\tvalid_1's rmse: 0.992216\n",
      "Partial score of fold 3 is: 0.5855878373132928\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.890753\tvalid_1's rmse: 0.989789\n",
      "[200]\ttraining's rmse: 0.822199\tvalid_1's rmse: 0.988307\n",
      "Early stopping, best iteration is:\n",
      "[140]\ttraining's rmse: 0.861191\tvalid_1's rmse: 0.987773\n",
      "Partial score of fold 4 is: 0.580129108259522\n",
      "Our oof cohen kappa score is:  0.5875510006650183\n",
      "kappa:  0.5875510006650183\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.5876  \u001b[0m | \u001b[0m 0.996   \u001b[0m | \u001b[0m 4.7     \u001b[0m | \u001b[0m 4.959   \u001b[0m | \u001b[0m 0.05595 \u001b[0m | \u001b[0m 14.02   \u001b[0m | \u001b[0m 9.801   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.893083\tvalid_1's rmse: 0.980151\n",
      "[200]\ttraining's rmse: 0.822609\tvalid_1's rmse: 0.977328\n",
      "Early stopping, best iteration is:\n",
      "[192]\ttraining's rmse: 0.827464\tvalid_1's rmse: 0.976933\n",
      "Partial score of fold 0 is: 0.5994219797534681\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.889933\tvalid_1's rmse: 0.990068\n",
      "[200]\ttraining's rmse: 0.82048\tvalid_1's rmse: 0.992372\n",
      "Early stopping, best iteration is:\n",
      "[167]\ttraining's rmse: 0.841215\tvalid_1's rmse: 0.989606\n",
      "Partial score of fold 1 is: 0.5886297227906995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.890997\tvalid_1's rmse: 0.987711\n",
      "[200]\ttraining's rmse: 0.821285\tvalid_1's rmse: 0.98792\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttraining's rmse: 0.856254\tvalid_1's rmse: 0.986558\n",
      "Partial score of fold 2 is: 0.5873771817117673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.892455\tvalid_1's rmse: 0.989973\n",
      "[200]\ttraining's rmse: 0.822055\tvalid_1's rmse: 0.986568\n",
      "[300]\ttraining's rmse: 0.768612\tvalid_1's rmse: 0.988123\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's rmse: 0.819035\tvalid_1's rmse: 0.986486\n",
      "Partial score of fold 3 is: 0.5963239037041401\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.89296\tvalid_1's rmse: 0.986648\n",
      "[200]\ttraining's rmse: 0.822133\tvalid_1's rmse: 0.982884\n",
      "[300]\ttraining's rmse: 0.768714\tvalid_1's rmse: 0.983401\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's rmse: 0.799432\tvalid_1's rmse: 0.982706\n",
      "Partial score of fold 4 is: 0.5863945020821256\n",
      "Our oof cohen kappa score is:  0.5912732061432237\n",
      "kappa:  0.5912732061432237\n",
      "| \u001b[95m 25      \u001b[0m | \u001b[95m 0.5913  \u001b[0m | \u001b[95m 0.8522  \u001b[0m | \u001b[95m 0.5142  \u001b[0m | \u001b[95m 4.795   \u001b[0m | \u001b[95m 0.04841 \u001b[0m | \u001b[95m 16.86   \u001b[0m | \u001b[95m 1.374   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.926068\tvalid_1's rmse: 0.983672\n",
      "[200]\ttraining's rmse: 0.866749\tvalid_1's rmse: 0.975101\n",
      "[300]\ttraining's rmse: 0.82364\tvalid_1's rmse: 0.975582\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's rmse: 0.865719\tvalid_1's rmse: 0.975051\n",
      "Partial score of fold 0 is: 0.5997797984406021\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.922363\tvalid_1's rmse: 0.995243\n",
      "[200]\ttraining's rmse: 0.863499\tvalid_1's rmse: 0.992198\n",
      "[300]\ttraining's rmse: 0.819857\tvalid_1's rmse: 0.992314\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's rmse: 0.858524\tvalid_1's rmse: 0.991676\n",
      "Partial score of fold 1 is: 0.5816512796366488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.923288\tvalid_1's rmse: 0.994\n",
      "[200]\ttraining's rmse: 0.86413\tvalid_1's rmse: 0.988059\n",
      "[300]\ttraining's rmse: 0.820458\tvalid_1's rmse: 0.989293\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's rmse: 0.863159\tvalid_1's rmse: 0.988039\n",
      "Partial score of fold 2 is: 0.5898822638696317\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.923054\tvalid_1's rmse: 0.996115\n",
      "[200]\ttraining's rmse: 0.864847\tvalid_1's rmse: 0.989497\n",
      "[300]\ttraining's rmse: 0.822091\tvalid_1's rmse: 0.989569\n",
      "Early stopping, best iteration is:\n",
      "[228]\ttraining's rmse: 0.851911\tvalid_1's rmse: 0.988549\n",
      "Partial score of fold 3 is: 0.59703964146353\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925185\tvalid_1's rmse: 0.99576\n",
      "[200]\ttraining's rmse: 0.866539\tvalid_1's rmse: 0.987902\n",
      "[300]\ttraining's rmse: 0.824471\tvalid_1's rmse: 0.986013\n",
      "[400]\ttraining's rmse: 0.788304\tvalid_1's rmse: 0.985477\n",
      "Early stopping, best iteration is:\n",
      "[342]\ttraining's rmse: 0.808827\tvalid_1's rmse: 0.98509\n",
      "Partial score of fold 4 is: 0.5844253783093074\n",
      "Our oof cohen kappa score is:  0.5888752468447644\n",
      "kappa:  0.5888752468447644\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.5889  \u001b[0m | \u001b[0m 0.9896  \u001b[0m | \u001b[0m 3.607   \u001b[0m | \u001b[0m 4.839   \u001b[0m | \u001b[0m 0.03521 \u001b[0m | \u001b[0m 14.98   \u001b[0m | \u001b[0m 4.051   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.928593\tvalid_1's rmse: 0.984531\n",
      "[200]\ttraining's rmse: 0.868776\tvalid_1's rmse: 0.974972\n",
      "[300]\ttraining's rmse: 0.826287\tvalid_1's rmse: 0.974618\n",
      "Early stopping, best iteration is:\n",
      "[230]\ttraining's rmse: 0.855145\tvalid_1's rmse: 0.973809\n",
      "Partial score of fold 0 is: 0.6031790759683753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925055\tvalid_1's rmse: 0.99351\n",
      "[200]\ttraining's rmse: 0.865874\tvalid_1's rmse: 0.987684\n",
      "[300]\ttraining's rmse: 0.823568\tvalid_1's rmse: 0.98876\n",
      "Early stopping, best iteration is:\n",
      "[208]\ttraining's rmse: 0.86199\tvalid_1's rmse: 0.987549\n",
      "Partial score of fold 1 is: 0.5882718539110046\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.926046\tvalid_1's rmse: 0.995454\n",
      "[200]\ttraining's rmse: 0.867354\tvalid_1's rmse: 0.987352\n",
      "Early stopping, best iteration is:\n",
      "[199]\ttraining's rmse: 0.867839\tvalid_1's rmse: 0.987282\n",
      "Partial score of fold 2 is: 0.5868403783922249\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925896\tvalid_1's rmse: 0.996299\n",
      "[200]\ttraining's rmse: 0.867471\tvalid_1's rmse: 0.989262\n",
      "[300]\ttraining's rmse: 0.825382\tvalid_1's rmse: 0.987852\n",
      "Early stopping, best iteration is:\n",
      "[264]\ttraining's rmse: 0.83975\tvalid_1's rmse: 0.987486\n",
      "Partial score of fold 3 is: 0.5914926738282588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.927134\tvalid_1's rmse: 0.99342\n",
      "[200]\ttraining's rmse: 0.868287\tvalid_1's rmse: 0.982817\n",
      "[300]\ttraining's rmse: 0.826121\tvalid_1's rmse: 0.98163\n",
      "[400]\ttraining's rmse: 0.791533\tvalid_1's rmse: 0.981501\n",
      "Early stopping, best iteration is:\n",
      "[340]\ttraining's rmse: 0.811869\tvalid_1's rmse: 0.98088\n",
      "Partial score of fold 4 is: 0.5901537383756877\n",
      "Our oof cohen kappa score is:  0.5909510922076098\n",
      "kappa:  0.5909510922076098\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.591   \u001b[0m | \u001b[0m 0.8988  \u001b[0m | \u001b[0m 4.674   \u001b[0m | \u001b[0m 0.5654  \u001b[0m | \u001b[0m 0.03296 \u001b[0m | \u001b[0m 16.67   \u001b[0m | \u001b[0m 1.25    \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.933169\tvalid_1's rmse: 0.986137\n",
      "[200]\ttraining's rmse: 0.875201\tvalid_1's rmse: 0.976116\n",
      "[300]\ttraining's rmse: 0.834656\tvalid_1's rmse: 0.97438\n",
      "[400]\ttraining's rmse: 0.799626\tvalid_1's rmse: 0.976205\n",
      "Early stopping, best iteration is:\n",
      "[303]\ttraining's rmse: 0.833474\tvalid_1's rmse: 0.974267\n",
      "Partial score of fold 0 is: 0.599243070409901\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.928545\tvalid_1's rmse: 0.994096\n",
      "[200]\ttraining's rmse: 0.871482\tvalid_1's rmse: 0.988519\n",
      "[300]\ttraining's rmse: 0.830279\tvalid_1's rmse: 0.991217\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's rmse: 0.871002\tvalid_1's rmse: 0.988423\n",
      "Partial score of fold 1 is: 0.5852299684335979\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.932216\tvalid_1's rmse: 0.996552\n",
      "[200]\ttraining's rmse: 0.874266\tvalid_1's rmse: 0.989784\n",
      "[300]\ttraining's rmse: 0.833055\tvalid_1's rmse: 0.989978\n",
      "Early stopping, best iteration is:\n",
      "[267]\ttraining's rmse: 0.845572\tvalid_1's rmse: 0.989246\n",
      "Partial score of fold 2 is: 0.5893454605500893\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.931152\tvalid_1's rmse: 0.99804\n",
      "[200]\ttraining's rmse: 0.872698\tvalid_1's rmse: 0.989311\n",
      "[300]\ttraining's rmse: 0.831198\tvalid_1's rmse: 0.986932\n",
      "[400]\ttraining's rmse: 0.796271\tvalid_1's rmse: 0.989376\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's rmse: 0.825059\tvalid_1's rmse: 0.986824\n",
      "Partial score of fold 3 is: 0.5925662804673435\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.931519\tvalid_1's rmse: 0.997135\n",
      "[200]\ttraining's rmse: 0.87463\tvalid_1's rmse: 0.98727\n",
      "[300]\ttraining's rmse: 0.833345\tvalid_1's rmse: 0.987957\n",
      "Early stopping, best iteration is:\n",
      "[243]\ttraining's rmse: 0.855766\tvalid_1's rmse: 0.986849\n",
      "Partial score of fold 4 is: 0.5808451532678196\n",
      "Our oof cohen kappa score is:  0.5893405225295401\n",
      "kappa:  0.5893405225295401\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5893  \u001b[0m | \u001b[0m 0.9297  \u001b[0m | \u001b[0m 4.469   \u001b[0m | \u001b[0m 1.09    \u001b[0m | \u001b[0m 0.03163 \u001b[0m | \u001b[0m 15.43   \u001b[0m | \u001b[0m 5.564   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.949693\tvalid_1's rmse: 0.992941\n",
      "[200]\ttraining's rmse: 0.894042\tvalid_1's rmse: 0.976787\n",
      "[300]\ttraining's rmse: 0.856728\tvalid_1's rmse: 0.974397\n",
      "[400]\ttraining's rmse: 0.825929\tvalid_1's rmse: 0.974621\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's rmse: 0.856728\tvalid_1's rmse: 0.974397\n",
      "Partial score of fold 0 is: 0.5993601411441315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.946374\tvalid_1's rmse: 0.998949\n",
      "[200]\ttraining's rmse: 0.890637\tvalid_1's rmse: 0.988236\n",
      "[300]\ttraining's rmse: 0.85319\tvalid_1's rmse: 0.987162\n",
      "[400]\ttraining's rmse: 0.82275\tvalid_1's rmse: 0.987686\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's rmse: 0.846241\tvalid_1's rmse: 0.986997\n",
      "Partial score of fold 1 is: 0.5871982472719199\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.94753\tvalid_1's rmse: 1.0001\n",
      "[200]\ttraining's rmse: 0.891989\tvalid_1's rmse: 0.987223\n",
      "[300]\ttraining's rmse: 0.854753\tvalid_1's rmse: 0.986716\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's rmse: 0.873752\tvalid_1's rmse: 0.986448\n",
      "Partial score of fold 2 is: 0.5886297227906995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.947089\tvalid_1's rmse: 1.00269\n",
      "[200]\ttraining's rmse: 0.891369\tvalid_1's rmse: 0.98945\n",
      "[300]\ttraining's rmse: 0.854178\tvalid_1's rmse: 0.986546\n",
      "[400]\ttraining's rmse: 0.823617\tvalid_1's rmse: 0.985851\n",
      "[500]\ttraining's rmse: 0.796651\tvalid_1's rmse: 0.985388\n",
      "[600]\ttraining's rmse: 0.772673\tvalid_1's rmse: 0.985977\n",
      "Early stopping, best iteration is:\n",
      "[518]\ttraining's rmse: 0.792261\tvalid_1's rmse: 0.985177\n",
      "Partial score of fold 3 is: 0.5991868547416994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.947909\tvalid_1's rmse: 1.00097\n",
      "[200]\ttraining's rmse: 0.892231\tvalid_1's rmse: 0.984637\n",
      "[300]\ttraining's rmse: 0.855578\tvalid_1's rmse: 0.981728\n",
      "[400]\ttraining's rmse: 0.82538\tvalid_1's rmse: 0.980976\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's rmse: 0.835626\tvalid_1's rmse: 0.980595\n",
      "Partial score of fold 4 is: 0.5933759409130268\n",
      "Our oof cohen kappa score is:  0.5934206323806498\n",
      "kappa:  0.5934206323806498\n",
      "| \u001b[95m 29      \u001b[0m | \u001b[95m 0.5934  \u001b[0m | \u001b[95m 0.8818  \u001b[0m | \u001b[95m 4.762   \u001b[0m | \u001b[95m 4.504   \u001b[0m | \u001b[95m 0.02612 \u001b[0m | \u001b[95m 16.9    \u001b[0m | \u001b[95m 1.395   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.927373\tvalid_1's rmse: 0.983765\n",
      "[200]\ttraining's rmse: 0.867432\tvalid_1's rmse: 0.974845\n",
      "[300]\ttraining's rmse: 0.824171\tvalid_1's rmse: 0.975333\n",
      "Early stopping, best iteration is:\n",
      "[270]\ttraining's rmse: 0.836066\tvalid_1's rmse: 0.97427\n",
      "Partial score of fold 0 is: 0.6021056199069732\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.923619\tvalid_1's rmse: 0.992031\n",
      "[200]\ttraining's rmse: 0.864343\tvalid_1's rmse: 0.9894\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's rmse: 0.873163\tvalid_1's rmse: 0.989128\n",
      "Partial score of fold 1 is: 0.5875561161516147\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925615\tvalid_1's rmse: 0.994306\n",
      "[200]\ttraining's rmse: 0.866425\tvalid_1's rmse: 0.987158\n",
      "[300]\ttraining's rmse: 0.823261\tvalid_1's rmse: 0.987831\n",
      "Early stopping, best iteration is:\n",
      "[201]\ttraining's rmse: 0.865907\tvalid_1's rmse: 0.987143\n",
      "Partial score of fold 2 is: 0.5863035750726826\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.924895\tvalid_1's rmse: 0.996168\n",
      "[200]\ttraining's rmse: 0.865654\tvalid_1's rmse: 0.987487\n",
      "[300]\ttraining's rmse: 0.822804\tvalid_1's rmse: 0.985168\n",
      "[400]\ttraining's rmse: 0.786428\tvalid_1's rmse: 0.986317\n",
      "Early stopping, best iteration is:\n",
      "[328]\ttraining's rmse: 0.812137\tvalid_1's rmse: 0.984961\n",
      "Partial score of fold 3 is: 0.5965028381439875\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.925875\tvalid_1's rmse: 0.99369\n",
      "[200]\ttraining's rmse: 0.865923\tvalid_1's rmse: 0.983853\n",
      "[300]\ttraining's rmse: 0.822824\tvalid_1's rmse: 0.982325\n",
      "[400]\ttraining's rmse: 0.786927\tvalid_1's rmse: 0.983191\n",
      "Early stopping, best iteration is:\n",
      "[314]\ttraining's rmse: 0.817464\tvalid_1's rmse: 0.981684\n",
      "Partial score of fold 4 is: 0.5853204345696793\n",
      "Our oof cohen kappa score is:  0.5904142356482531\n",
      "kappa:  0.5904142356482531\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.5904  \u001b[0m | \u001b[0m 0.9678  \u001b[0m | \u001b[0m 2.411   \u001b[0m | \u001b[0m 4.546   \u001b[0m | \u001b[0m 0.03284 \u001b[0m | \u001b[0m 16.85   \u001b[0m | \u001b[0m 1.339   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.937862\tvalid_1's rmse: 0.98977\n",
      "[200]\ttraining's rmse: 0.879441\tvalid_1's rmse: 0.978164\n",
      "[300]\ttraining's rmse: 0.83804\tvalid_1's rmse: 0.979481\n",
      "Early stopping, best iteration is:\n",
      "[204]\ttraining's rmse: 0.877345\tvalid_1's rmse: 0.978085\n",
      "Partial score of fold 0 is: 0.5940546994464578\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.933382\tvalid_1's rmse: 0.996375\n",
      "[200]\ttraining's rmse: 0.875434\tvalid_1's rmse: 0.989981\n",
      "[300]\ttraining's rmse: 0.833514\tvalid_1's rmse: 0.989737\n",
      "[400]\ttraining's rmse: 0.799436\tvalid_1's rmse: 0.991274\n",
      "Early stopping, best iteration is:\n",
      "[311]\ttraining's rmse: 0.829462\tvalid_1's rmse: 0.98954\n",
      "Partial score of fold 1 is: 0.5888086572305469\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.936017\tvalid_1's rmse: 0.997902\n",
      "[200]\ttraining's rmse: 0.876969\tvalid_1's rmse: 0.987996\n",
      "[300]\ttraining's rmse: 0.835887\tvalid_1's rmse: 0.987625\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's rmse: 0.851569\tvalid_1's rmse: 0.987168\n",
      "Partial score of fold 2 is: 0.5861246406328351\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.93443\tvalid_1's rmse: 0.997959\n",
      "[200]\ttraining's rmse: 0.876782\tvalid_1's rmse: 0.988285\n",
      "[300]\ttraining's rmse: 0.836601\tvalid_1's rmse: 0.988352\n",
      "Early stopping, best iteration is:\n",
      "[276]\ttraining's rmse: 0.845432\tvalid_1's rmse: 0.988241\n",
      "Partial score of fold 3 is: 0.592387346027496\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.936114\tvalid_1's rmse: 0.996914\n",
      "[200]\ttraining's rmse: 0.877828\tvalid_1's rmse: 0.985945\n",
      "[300]\ttraining's rmse: 0.836627\tvalid_1's rmse: 0.984635\n",
      "[400]\ttraining's rmse: 0.80271\tvalid_1's rmse: 0.984799\n",
      "Early stopping, best iteration is:\n",
      "[335]\ttraining's rmse: 0.823907\tvalid_1's rmse: 0.983905\n",
      "Partial score of fold 4 is: 0.5808451532678196\n",
      "Our oof cohen kappa score is:  0.5888394564074739\n",
      "kappa:  0.5888394564074739\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.5888  \u001b[0m | \u001b[0m 0.9565  \u001b[0m | \u001b[0m 3.159   \u001b[0m | \u001b[0m 0.5322  \u001b[0m | \u001b[0m 0.02882 \u001b[0m | \u001b[0m 16.77   \u001b[0m | \u001b[0m 3.628   \u001b[0m |\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.915089\tvalid_1's rmse: 0.984539\n",
      "[200]\ttraining's rmse: 0.85019\tvalid_1's rmse: 0.979285\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 0.873991\tvalid_1's rmse: 0.978911\n",
      "Partial score of fold 0 is: 0.5947703368207258\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.910967\tvalid_1's rmse: 0.991897\n",
      "[200]\ttraining's rmse: 0.846123\tvalid_1's rmse: 0.990044\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttraining's rmse: 0.870173\tvalid_1's rmse: 0.989317\n",
      "Partial score of fold 1 is: 0.5914926738282588\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.912823\tvalid_1's rmse: 0.992602\n",
      "[200]\ttraining's rmse: 0.848764\tvalid_1's rmse: 0.987652\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's rmse: 0.8743\tvalid_1's rmse: 0.987174\n",
      "Partial score of fold 2 is: 0.5916716082681062\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.912286\tvalid_1's rmse: 0.99163\n",
      "[200]\ttraining's rmse: 0.846912\tvalid_1's rmse: 0.987919\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's rmse: 0.849666\tvalid_1's rmse: 0.987481\n",
      "Partial score of fold 3 is: 0.5907769360688689\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.913661\tvalid_1's rmse: 0.992921\n",
      "[200]\ttraining's rmse: 0.848998\tvalid_1's rmse: 0.986248\n",
      "[300]\ttraining's rmse: 0.800394\tvalid_1's rmse: 0.987508\n",
      "Early stopping, best iteration is:\n",
      "[202]\ttraining's rmse: 0.847827\tvalid_1's rmse: 0.986142\n",
      "Partial score of fold 4 is: 0.590690772131911\n",
      "Our oof cohen kappa score is:  0.5905931878347054\n",
      "kappa:  0.5905931878347054\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.5906  \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 0.1668  \u001b[0m | \u001b[0m 0.1237  \u001b[0m | \u001b[0m 0.03562 \u001b[0m | \u001b[0m 13.18   \u001b[0m | \u001b[0m 3.883   \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def LGB_Beyes(subsample_freq,\n",
    "                    learning_rate,\n",
    "                    feature_fraction,\n",
    "                    max_depth,\n",
    "                    lambda_l1,\n",
    "                    lambda_l2):\n",
    "    params={}\n",
    "    params['subsample_freq']=subsample_freq\n",
    "    params['learning_rate']=learning_rate\n",
    "    params['feature_fraction']=feature_fraction\n",
    "    params['lambda_l1']=lambda_l1\n",
    "    params['lambda_l2']=lambda_l2\n",
    "    params['max_depth']=max_depth\n",
    "    lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals,ps=params)\n",
    "    print('kappa: ',lgb_model.score)\n",
    "    return lgb_model.score\n",
    "\n",
    "bounds_LGB = {\n",
    "    'subsample_freq': (1, 10),\n",
    "    'learning_rate': (0.025, 0.5),\n",
    "    'feature_fraction': (0.5, 1),\n",
    "    'lambda_l1': (0, 5),\n",
    "    'lambda_l2': (0, 5),\n",
    "    'max_depth': (13, 17),\n",
    "}\n",
    "\n",
    "LGB_BO = BayesianOptimization(LGB_Beyes, bounds_LGB, random_state=1029)\n",
    "import warnings\n",
    "init_points = 16\n",
    "n_iter = 16\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.949693\tvalid_1's rmse: 0.992941\n",
      "[200]\ttraining's rmse: 0.894042\tvalid_1's rmse: 0.976787\n",
      "[300]\ttraining's rmse: 0.856728\tvalid_1's rmse: 0.974397\n",
      "[400]\ttraining's rmse: 0.825929\tvalid_1's rmse: 0.974621\n",
      "Early stopping, best iteration is:\n",
      "[300]\ttraining's rmse: 0.856728\tvalid_1's rmse: 0.974397\n",
      "Partial score of fold 0 is: 0.5993601411441315\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.946374\tvalid_1's rmse: 0.998949\n",
      "[200]\ttraining's rmse: 0.890637\tvalid_1's rmse: 0.988236\n",
      "[300]\ttraining's rmse: 0.85319\tvalid_1's rmse: 0.987162\n",
      "[400]\ttraining's rmse: 0.82275\tvalid_1's rmse: 0.987686\n",
      "Early stopping, best iteration is:\n",
      "[322]\ttraining's rmse: 0.846241\tvalid_1's rmse: 0.986997\n",
      "Partial score of fold 1 is: 0.5871982472719199\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.94753\tvalid_1's rmse: 1.0001\n",
      "[200]\ttraining's rmse: 0.891989\tvalid_1's rmse: 0.987223\n",
      "[300]\ttraining's rmse: 0.854753\tvalid_1's rmse: 0.986716\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's rmse: 0.873752\tvalid_1's rmse: 0.986448\n",
      "Partial score of fold 2 is: 0.5886297227906995\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.947089\tvalid_1's rmse: 1.00269\n",
      "[200]\ttraining's rmse: 0.891369\tvalid_1's rmse: 0.98945\n",
      "[300]\ttraining's rmse: 0.854178\tvalid_1's rmse: 0.986546\n",
      "[400]\ttraining's rmse: 0.823617\tvalid_1's rmse: 0.985851\n",
      "[500]\ttraining's rmse: 0.796651\tvalid_1's rmse: 0.985388\n",
      "[600]\ttraining's rmse: 0.772673\tvalid_1's rmse: 0.985977\n",
      "Early stopping, best iteration is:\n",
      "[518]\ttraining's rmse: 0.792261\tvalid_1's rmse: 0.985177\n",
      "Partial score of fold 3 is: 0.5991868547416994\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's rmse: 0.947909\tvalid_1's rmse: 1.00097\n",
      "[200]\ttraining's rmse: 0.892231\tvalid_1's rmse: 0.984637\n",
      "[300]\ttraining's rmse: 0.855578\tvalid_1's rmse: 0.981728\n",
      "[400]\ttraining's rmse: 0.82538\tvalid_1's rmse: 0.980976\n",
      "Early stopping, best iteration is:\n",
      "[365]\ttraining's rmse: 0.835626\tvalid_1's rmse: 0.980595\n",
      "Partial score of fold 4 is: 0.5933759409130268\n",
      "Our oof cohen kappa score is:  0.5934206323806498\n",
      "[0]\ttrain-rmse:1.85626\tval-rmse:1.85708\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01305\tval-rmse:1.15305\n",
      "[200]\ttrain-rmse:0.74419\tval-rmse:1.01365\n",
      "[300]\ttrain-rmse:0.636415\tval-rmse:0.990979\n",
      "[400]\ttrain-rmse:0.583629\tval-rmse:0.988145\n",
      "[500]\ttrain-rmse:0.550069\tval-rmse:0.988919\n",
      "Stopping. Best iteration:\n",
      "[432]\ttrain-rmse:0.571153\tval-rmse:0.988073\n",
      "\n",
      "Partial score of fold 0 is: 0.5836779575195714\n",
      "[0]\ttrain-rmse:1.85621\tval-rmse:1.85749\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01177\tval-rmse:1.16743\n",
      "[200]\ttrain-rmse:0.739377\tval-rmse:1.02832\n",
      "[300]\ttrain-rmse:0.632137\tval-rmse:1.00577\n",
      "[400]\ttrain-rmse:0.577776\tval-rmse:1.00373\n",
      "[500]\ttrain-rmse:0.54612\tval-rmse:1.00315\n",
      "Stopping. Best iteration:\n",
      "[499]\ttrain-rmse:0.546226\tval-rmse:1.00313\n",
      "\n",
      "Partial score of fold 1 is: 0.5716309510051912\n",
      "[0]\ttrain-rmse:1.85632\tval-rmse:1.85736\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01331\tval-rmse:1.15895\n",
      "[200]\ttrain-rmse:0.745167\tval-rmse:1.02083\n",
      "[300]\ttrain-rmse:0.644558\tval-rmse:1.00112\n",
      "[400]\ttrain-rmse:0.58828\tval-rmse:0.999338\n",
      "Stopping. Best iteration:\n",
      "[392]\ttrain-rmse:0.591595\tval-rmse:0.999167\n",
      "\n",
      "Partial score of fold 2 is: 0.5780725908396996\n",
      "[0]\ttrain-rmse:1.85629\tval-rmse:1.85734\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.00992\tval-rmse:1.16122\n",
      "[200]\ttrain-rmse:0.736853\tval-rmse:1.02431\n",
      "[300]\ttrain-rmse:0.63559\tval-rmse:1.00334\n",
      "[400]\ttrain-rmse:0.581993\tval-rmse:1.00114\n",
      "[500]\ttrain-rmse:0.552083\tval-rmse:1.0017\n",
      "Stopping. Best iteration:\n",
      "[409]\ttrain-rmse:0.578708\tval-rmse:1.0011\n",
      "\n",
      "Partial score of fold 3 is: 0.5764621808810726\n",
      "[0]\ttrain-rmse:1.85626\tval-rmse:1.85751\n",
      "Multiple eval metrics have been passed: 'val-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until val-rmse hasn't improved in 100 rounds.\n",
      "[100]\ttrain-rmse:1.01758\tval-rmse:1.16093\n",
      "[200]\ttrain-rmse:0.746663\tval-rmse:1.02153\n",
      "[300]\ttrain-rmse:0.644667\tval-rmse:0.998997\n",
      "[400]\ttrain-rmse:0.584677\tval-rmse:0.995327\n",
      "[500]\ttrain-rmse:0.543467\tval-rmse:0.995159\n",
      "Stopping. Best iteration:\n",
      "[443]\ttrain-rmse:0.564369\tval-rmse:0.994915\n",
      "\n",
      "Partial score of fold 4 is: 0.5715365681599514\n",
      "Our oof cohen kappa score is:  0.574881185864204\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#cat_model = Catb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "lgb_model = Lgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals, ps=LGB_BO.max['params'])\n",
    "xgb_model = Xgb_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cnn_model = Cnn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)\n",
    "# nn_model = Nn_Model(reduce_train, ajusted_test, features, categoricals=categoricals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "weights = {'lbg': 0.80, 'cat': 0, 'xgb': 0.20, 'nn': 0.00}\n",
    "\n",
    "final_pred = (lgb_model.y_pred * weights['lbg']) + (xgb_model.y_pred * weights['xgb'])\n",
    "#final_pred = cnn_model.y_pred\n",
    "print(final_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame([(round(a, 2), round(b, 2), round(c, 2), round(d, 2)) for a, b, c, d in zip(lgb_model.y_pred, cat_model.y_pred, xgb_model.y_pred, nn_model.y_pred)], columns=['lgb', 'cat', 'xgb', 'nn']).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 1.292420983600158, 1: 1.7289992583157625, 2: 1.9383877823834554}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3    0.500\n",
       "0    0.239\n",
       "1    0.136\n",
       "2    0.125\n",
       "Name: accuracy_group, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dist = Counter(reduce_train['accuracy_group'])\n",
    "for k in dist:\n",
    "    dist[k] /= len(reduce_train)\n",
    "reduce_train['accuracy_group'].hist()\n",
    "\n",
    "acum = 0\n",
    "bound = {}\n",
    "for i in range(3):\n",
    "    acum += dist[i]\n",
    "    bound[i] = np.percentile(final_pred, acum * 100)\n",
    "print(bound)\n",
    "\n",
    "def classify(x):\n",
    "    if x <= bound[0]:\n",
    "        return 0\n",
    "    elif x <= bound[1]:\n",
    "        return 1\n",
    "    elif x <= bound[2]:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3\n",
    "    \n",
    "final_pred = np.array(list(map(classify, final_pred)))\n",
    "\n",
    "sample_submission['accuracy_group'] = final_pred.astype(int)\n",
    "sample_submission.to_csv('submission.csv', index=False)\n",
    "sample_submission['accuracy_group'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
